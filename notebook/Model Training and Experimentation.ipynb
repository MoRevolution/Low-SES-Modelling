{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"f739cf8d2925405c81e4f3b7efc90668","deepnote_cell_type":"markdown"},"source":["### Import Required Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"06f1584f56e34b68bc6892ed1f4799f5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1679435620340,"source_hash":"926f97ae"},"outputs":[],"source":["import numpy as np\n","import json\n","import glob\n","import re\n","\n","#Gensim\n","import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","from gensim.corpora import Dictionary\n","from gensim.models import LdaModel\n","\n","#spacy\n","import spacy\n","from nltk.corpus import stopwords\n","from nltk.tokenize import sent_tokenize\n","from nltk.stem.wordnet import WordNetLemmatizer\n","\n","#vis\n","import pyLDAvis\n","import pyLDAvis.gensim_models\n","#nltk.download(punkt)\n","#nltk.download(wordnet) \n"]},{"cell_type":"markdown","metadata":{"cell_id":"e7b1a362c8934110b6cf61ef199d4a63","deepnote_cell_type":"markdown"},"source":["### Data Input "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"605507f0205247f092c843b5af676678","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":20,"execution_start":1679435622666,"source_hash":"2476592d"},"outputs":[],"source":["\n","##\"local_data.json\" deleted from this repo for to preserve confidentiality of narratives used during training\n","def load_data(file):\n","    with open (file, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f) \n","    return (data)\n","\n","def write_data(file, data):\n","    with open (file, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(data, f, indent=4)\n","\n","stories = load_data(\"local_data.json\")[\"File\"]\n","print(stories[0])"]},{"cell_type":"markdown","metadata":{"cell_id":"2314631364ab4474af4676c1f491b910","deepnote_cell_type":"markdown"},"source":["### Pre-process and vectorize the documents "]},{"cell_type":"markdown","metadata":{"cell_id":"1cf0ae5c21c94a339e321925855b5273","deepnote_cell_type":"markdown","tags":[]},"source":["In case prompted to install stopwords, use \"nltk.download(stopwords)\"."]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"66e4fc6a978541b4815af623fd458f2e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":57,"execution_start":1679435028632,"source_hash":"524ca162","tags":[]},"outputs":[],"source":["import nltk\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e1388ccdec914a43807f03f828fb0601","collapsed":true,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1757,"execution_start":1679435782205,"id":"MFyKGQ-x3IZV","source_hash":"bcf3e434"},"outputs":[],"source":["#Lemmatization\n","stops = set(stopwords.words(\"english\"))\n","\n","def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n","    #Use \"python -m spacy download en_core_web_sm\" in a terminal if error [E050]\n","    nlp = spacy.load(\"en_core_web_sm\",disable=[\"parser\",\"ner\"])\n","    texts_out = []\n","\n","    for text in texts:\n","        doc = nlp(text)\n","        new_text = []\n","        for token in doc:\n","            if token.pos_ in allowed_postags:\n","                new_text.append(token.lemma_)\n","        final = \" \".join(new_text)\n","        texts_out.append(final)\n","        \n","    return(texts_out)\n","\n","lemmatized_texts = lemmatization(stories)\n","# print(lemmatized_texts[0][:100])"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ef57ceff04d9458a8d6f611582b7cfa4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":15,"execution_start":1679435791250,"source_hash":"27ae6109"},"outputs":[],"source":["#deaccenting and removing stop words\n","def gen_words(texts):\n","    final = []\n","    for text in texts:\n","        new = gensim.utils.simple_preprocess(text, deacc=True)\n","        final.append(new)\n","    return (final)\n","\n","data_words = gen_words(lemmatized_texts)\n","print (data_words[0][0:20])"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e21de1bdfd4e49b99dbc9517e374fdd0","collapsed":true,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1679435794464,"source_hash":"be905800"},"outputs":[],"source":["#BIGRAMS AND TRIGRAMS\n","bigram_phrases = gensim.models.Phrases(data_words, min_count=2,threshold=50)\n","trigram_phrases = gensim.models.Phrases(bigram_phrases[data_words],threshold=50)\n","\n","bigram = gensim.models.phrases.Phraser(bigram_phrases)\n","trigram = gensim.models.phrases.Phraser(trigram_phrases)\n","\n","def make_bigrams(texts):\n","    return(bigram[doc] for doc in texts)\n","\n","def make_trigrams(texts): \n","    return(trigram[bigram[doc]] for doc in texts)\n","\n","data_bigrams = make_bigrams(data_words)\n","data_bigrams_trigrams = make_trigrams(data_bigrams)\n","\n","data_bigrams_trigrams = list(data_bigrams_trigrams)\n","print(data_bigrams_trigrams[:1])"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4e9380edb2a64791b76ac0ee1926eb7b","collapsed":true,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1679435799885,"source_hash":"6e9d5d8b"},"outputs":[],"source":["#TF-IDF REMOVAL\n","from gensim.models import TfidfModel\n","\n","id2word = corpora.Dictionary(data_bigrams_trigrams)\n","\n","texts = data_bigrams_trigrams\n","print(texts[0][:20])\n","\n","corpus = [id2word.doc2bow(text) for text in texts]\n","print (corpus[0][0:20])\n","\n","tfidf = TfidfModel(corpus, id2word=id2word)\n","\n","low_value = 0.03\n","words  = []\n","words_missing_in_tfidf = []\n","for i in range(0, len(corpus)):\n","    bow = corpus[i]\n","    low_value_words = [] #reinitialize to be safe. You can skip this.\n","    tfidf_ids = [id for id, value in tfidf[bow]]\n","    bow_ids = [id for id, value in bow]\n","    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n","    drops = low_value_words+words_missing_in_tfidf\n","    for item in drops:\n","        words.append(id2word[item])\n","    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids] # The words with tf-idf socre 0 will be missing\n","\n","    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n","    corpus[i] = new_bow"]},{"cell_type":"markdown","metadata":{"cell_id":"91d40956b4144011a96e284d6b6e6662","deepnote_cell_type":"markdown"},"source":["###  Initial Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"03edae44d1dd46ddb2ff319b2c19fc62","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":524,"execution_start":1679435804375,"id":"Edw7Y3MIJnLK","source_hash":"2d9692d1"},"outputs":[],"source":["# Set training parameters.\n","num_topics = 10\n","chunksize = 2000\n","passes = 20\n","iterations = 400\n","eval_every = 1  # Dont evaluate model perplexity, takes too much time\n","\n","lda_model = LdaModel(\n","    corpus=corpus, \n","    id2word=id2word,\n","    chunksize=chunksize,\n","    alpha=\"auto\",\n","    eta=\"auto\",\n","    iterations=iterations,\n","    num_topics=num_topics,\n","    passes=passes,\n","    eval_every=eval_every\n",")"]},{"cell_type":"markdown","metadata":{"cell_id":"e49f5661d5614f70ac5ea8b46e285df8","deepnote_cell_type":"markdown"},"source":["#### Save LDA Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"861139ddde054e3fa12ce36ba698db75","deepnote_cell_type":"code"},"outputs":[],"source":["#lda_model.save(\"Models/test_model_1.model\")"]},{"cell_type":"markdown","metadata":{"cell_id":"956110eb240040969854975a4e957883","deepnote_cell_type":"markdown"},"source":["#### Top topics detected by model (visualize for clusters)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"5a38a7a3c3fd4587a679cbee2550826b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":10,"execution_start":1679435810653,"source_hash":"eb614cfe"},"outputs":[],"source":["top_topics = lda_model.top_topics(corpus)\n","\n","# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n","avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n","print(f'Average topic coherence: %.4f. % avg_topic_coherence')\n","\n","from pprint import pprint\n","print(top_topics)"]},{"cell_type":"markdown","metadata":{"cell_id":"ea5f5675b1484b2da5ac73a8ca085dd0","deepnote_cell_type":"markdown"},"source":["##### Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"81835a1821a447f48dec5c28caa8601b","colab":{"base_uri":"https://localhost:8080/","height":951},"collapsed":true,"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1067,"execution_start":1679435864364,"id":"vhwBJnIhT9VZ","outputId":"607d7393-24e0-42c4-ba97-9a7d0bbf94e1","source_hash":"5133d4ec"},"outputs":[],"source":["#use \"pip install pyLDAvis\" if the pyLDAvis library isn't installed on your system\n","import pyLDAvis\n","import pyLDAvis.gensim_models\n","\n","pyLDAvis.enable_notebook()\n","vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds=\"mmds\", R=30)\n","vis"]},{"cell_type":"markdown","metadata":{"cell_id":"7af12e28d98f4b9183d27d93dcc4b0b6","deepnote_cell_type":"markdown"},"source":["#### Evaluating Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"10e6037bd39144f188a611dcb17977ea","deepnote_cell_type":"code","id":"cskTzFfzR-Kp"},"outputs":[],"source":["new_model = gensim.models.ldamodel.LdaModel.load(\"Models\\Model V1\\test_model_1.model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f158ecc1ca1f45d6a1fb1269e3a055b2","deepnote_cell_type":"code"},"outputs":[],"source":["\n","\"\"\"Corpus has bee taken out here, modify \"Data Input\" with \n","new data to evaluate model.\n","\"\"\"\n","\n","#testing the loaded model\n","test_doc = corpus[-1]\n","\n","vector = new_model[test_doc]\n","\n","#logfile = open('Evaluation/For Model V1/Story_1.txt', 'a')\n","# print(new_model.show_topics(num_topics=10, num_words=10, formatted=False), file = logfile)\n","# logfile.close()\n","\n","#Sort to arrange topics based on priority or similarity. \n","def Sort(sub_li):\n","    sub_li.sort(key = lambda x: x[1])\n","    sub_li.reverse()\n","    return(sub_li)\n","new_vector = Sort(vector)\n","print(new_vector)#last story is most similar with topic 2"]},{"cell_type":"markdown","metadata":{"cell_id":"b16ef246e59d4346af8015cc7d695475","deepnote_cell_type":"markdown"},"source":["### Tuning LDA Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b7747f462edb44888690c66f3778b119","deepnote_cell_type":"code"},"outputs":[],"source":["#Compute Coherence Score \n","coherence_model_lda = CoherenceModel(\n","    model = lda_model,\n","    texts = texts, \n","    dictionary = id2word, \n","    coherence = 'c_v'\n",")\n","coherence_lda = coherence_model_lda.get_coherence()\n","print('Coherence Score: ', coherence_lda)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"7d7dd70a7c474578bedcbf0310e36756","deepnote_cell_type":"code"},"outputs":[],"source":["#Using a function to find the most optimal number of topics for a better coherence score. \n","\"\"\"Source_1 = https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know\"\"\"\n","\"\"\"Source_2 = https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#16buildingldamalletmodel\"\"\"\n","\n","def compute_coherence_values(chunksize, passes, iterations, eval_every, dictionary, corpus, texts, limit, start=2, step=3):\n","    \"\"\"\n","    Compute c_v coherence for various number of topics\n","\n","    Parameters:\n","    ----------\n","    dictionary : Gensim dictionary\n","    corpus : Gensim corpus\n","    texts : List of input texts\n","    limit : Max num of topics\n","\n","    Returns:\n"," \n"," -------\n","    model_list : List of LDA topic models\n","    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n","    \"\"\"\n","    coherence_values = []\n","    model_list = []\n","    for num_topics in range(start, limit, step):\n","        model = LdaModel(\n","        corpus=corpus, \n","        id2word=id2word,\n","        chunksize=chunksize,\n","        alpha=\"auto\",\n","        eta=\"auto\",\n","        iterations=iterations,\n","        num_topics=num_topics,\n","        passes=passes,\n","        eval_every=eval_every\n","        )\n","        model_list.append(model)\n","        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n","        coherence_values.append(coherencemodel.get_coherence())\n","\n","    return model_list, coherence_values"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"768f587d879544088253a5995e4e3fb9","deepnote_cell_type":"code"},"outputs":[],"source":["model_list, coherence_values = compute_coherence_values(\n","    dictionary=id2word, \n","    corpus=corpus, \n","    texts=texts, \n","    start=2, \n","    limit=40, \n","    step=4, \n","    chunksize = 2000, \n","    passes = 20, \n","    iterations = 400,\n","    eval_every = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"0b59edcf093c4ed18813d200102ed7a0","collapsed":true,"deepnote_cell_type":"code"},"outputs":[],"source":["# Show graph\n","import matplotlib.pyplot as plt \n","import pandas as pd\n","\n","limit=40; start=2; step=4\n","x = range(start, limit, step)\n","plt.plot(x, coherence_values)\n","plt.xlabel(\"Num Topics\")\n","plt.ylabel(\"Coherence score\")\n","plt.legend((\"coherence_values\"), loc='best')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b8374f0f1a6a4d86a8e3b57d6df84e01","deepnote_cell_type":"code","scrolled":true},"outputs":[],"source":["#Extracting the topic that gives the best results. \n","best_result_model = coherence_values.index(max(coherence_values))\n","optimal_model = model_list[best_result_model]\n","print(f'''{x[best_result_model]} topics give the highest coherence score of {coherence_values[best_result_model]} for this specific model''')"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"e029f940b84545cabb38d9ed63e96ec0","collapsed":true,"deepnote_cell_type":"code"},"outputs":[],"source":["pyLDAvis.enable_notebook()\n","vis = pyLDAvis.gensim_models.prepare(optimal_model, corpus, id2word, mds=\"mmds\", R=30)\n","vis"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4d833277159e49f5ab37a89052dbd944","deepnote_cell_type":"code"},"outputs":[],"source":["# optimal_model.save(\"Models/Model V2/test_model_2.model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"957103c33ec748f2a257ae1bed564be1","deepnote_cell_type":"code"},"outputs":[],"source":["results = optimal_model[corpus]\n","corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in results]\n","print(corpus_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"99978ae0174240cd847ff86504cca2c3","deepnote_cell_type":"code"},"outputs":[],"source":["topics = [[(term, round(wt, 3)) for term, wt in optimal_model.show_topic(n, topn=20)] for n in range(0, optimal_model.num_topics)]\n","# set column width\n","pd.set_option('display.max_colwidth', -1)\n","topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, optimal_model.num_topics+1)] )\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","tags":[]},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e63053c0-dc47-4e88-9f8d-a68d759ee1ee' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Demo V1.1","provenance":[]},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"8334b3f5a20048eb9f2d9c17d5f7adf4","kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":0}
