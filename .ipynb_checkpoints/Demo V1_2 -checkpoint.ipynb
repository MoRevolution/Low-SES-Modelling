{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwagbsqJC-0j"
   },
   "source": [
    "# In this version I made sure that all packages necessary for the code to run are a part of the code instead of having the user install the necessary packages manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vDJXBjEn1DmM"
   },
   "outputs": [],
   "source": [
    "#Subject to change, only using one file to train initial model. \n",
    "corpus = \"So I'm a young first gen college graduate, my dad joined the military as soon as he could and my mom dropped out at 16. I never really understood how different I was until I started hanging out with people in the same major as me (Marine Science). I always felt like I missed a crucial stage growing up where my interests would've been nurtured. Most of my studies I just did independently. I hated my teachers in high school because they only seemed to provide their helping hands to the kids who needed it least. I grew a bit of an unhealthy resentment to the preppy kids in my angst-ridden phase. I never really thought of going to college, it wasn't talked about, even with my other siblings. I just kind of wound up there and more or less, ended up winging it. Fast forward a few years and I am succeeding as best I can in classes and still feel like I'm missing something despite usually being near the top of most of my classes, doing climate change research as an undergraduate, leading study sessions with people in the honors college at my university and having many intelligent and motivating friends winning prestigious scholarships. I always felt like I got the concepts of the classes but everybody else seemed to understand the networking and scholarship and opportunity aspects of college. I graduated from a big school with my degree, my peers thought very highly of me, but I always felt less than everyone else. I felt like everyone else had a plan, knew what they were doing. So fast forward some more and here I am. I finally got my first good job in my field and I never really felt more out of place than here. I want to fit in, everybody is so nice, professional and scholarly. All I know how to do is memorize information and regurgitate it on a test and somehow do well. It just feels weird. Maybe it's a confidence thing? I know I can do whatever is needed to be done, I just don't know if I have any thing new to offer or worthwhile to contribute.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and vectorize the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "id": "MFyKGQ-x3IZV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['young',\n",
       "  'first',\n",
       "  'gen',\n",
       "  'college',\n",
       "  'graduate',\n",
       "  'dad',\n",
       "  'joined',\n",
       "  'the',\n",
       "  'military',\n",
       "  'soon',\n",
       "  'could',\n",
       "  'and',\n",
       "  'mom',\n",
       "  'dropped',\n",
       "  'out'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'understood',\n",
       "  'how',\n",
       "  'different',\n",
       "  'was',\n",
       "  'until',\n",
       "  'started',\n",
       "  'hanging',\n",
       "  'out',\n",
       "  'with',\n",
       "  'people',\n",
       "  'the',\n",
       "  'same',\n",
       "  'major',\n",
       "  'marine',\n",
       "  'science'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'missed',\n",
       "  'crucial',\n",
       "  'stage',\n",
       "  'growing',\n",
       "  'where',\n",
       "  'interests',\n",
       "  'would',\n",
       "  'been',\n",
       "  'nurtured'],\n",
       " ['most', 'studies', 'just', 'did', 'independently'],\n",
       " ['hated',\n",
       "  'teachers',\n",
       "  'high',\n",
       "  'school',\n",
       "  'because',\n",
       "  'they',\n",
       "  'only',\n",
       "  'seemed',\n",
       "  'provide',\n",
       "  'their',\n",
       "  'helping',\n",
       "  'hands',\n",
       "  'the',\n",
       "  'kids',\n",
       "  'who',\n",
       "  'needed',\n",
       "  'least'],\n",
       " ['grew',\n",
       "  'bit',\n",
       "  'unhealthy',\n",
       "  'resentment',\n",
       "  'the',\n",
       "  'preppy',\n",
       "  'kids',\n",
       "  'angst',\n",
       "  'ridden',\n",
       "  'phase'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'thought',\n",
       "  'going',\n",
       "  'college',\n",
       "  'wasn',\n",
       "  'talked',\n",
       "  'about',\n",
       "  'even',\n",
       "  'with',\n",
       "  'other',\n",
       "  'siblings'],\n",
       " ['just', 'kind', 'wound', 'there', 'and', 'more', 'less', 'ended', 'winging'],\n",
       " ['fast',\n",
       "  'forward',\n",
       "  'few',\n",
       "  'years',\n",
       "  'and',\n",
       "  'succeeding',\n",
       "  'best',\n",
       "  'can',\n",
       "  'classes',\n",
       "  'and',\n",
       "  'still',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'missing',\n",
       "  'something',\n",
       "  'despite',\n",
       "  'usually',\n",
       "  'being',\n",
       "  'near',\n",
       "  'the',\n",
       "  'top',\n",
       "  'most',\n",
       "  'classes',\n",
       "  'doing',\n",
       "  'climate',\n",
       "  'change',\n",
       "  'research',\n",
       "  'undergraduate',\n",
       "  'leading',\n",
       "  'study',\n",
       "  'sessions',\n",
       "  'with',\n",
       "  'people',\n",
       "  'the',\n",
       "  'honors',\n",
       "  'college',\n",
       "  'university',\n",
       "  'and',\n",
       "  'having',\n",
       "  'many',\n",
       "  'intelligent',\n",
       "  'and',\n",
       "  'motivating',\n",
       "  'friends',\n",
       "  'winning',\n",
       "  'prestigious',\n",
       "  'scholarships'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'got',\n",
       "  'the',\n",
       "  'concepts',\n",
       "  'the',\n",
       "  'classes',\n",
       "  'but',\n",
       "  'everybody',\n",
       "  'else',\n",
       "  'seemed',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'networking',\n",
       "  'and',\n",
       "  'scholarship',\n",
       "  'and',\n",
       "  'opportunity',\n",
       "  'aspects',\n",
       "  'college'],\n",
       " ['graduated',\n",
       "  'from',\n",
       "  'big',\n",
       "  'school',\n",
       "  'with',\n",
       "  'degree',\n",
       "  'peers',\n",
       "  'thought',\n",
       "  'very',\n",
       "  'highly',\n",
       "  'but',\n",
       "  'always',\n",
       "  'felt',\n",
       "  'less',\n",
       "  'than',\n",
       "  'everyone',\n",
       "  'else'],\n",
       " ['felt',\n",
       "  'like',\n",
       "  'everyone',\n",
       "  'else',\n",
       "  'had',\n",
       "  'plan',\n",
       "  'knew',\n",
       "  'what',\n",
       "  'they',\n",
       "  'were',\n",
       "  'doing'],\n",
       " ['fast', 'forward', 'some', 'more', 'and', 'here'],\n",
       " ['finally',\n",
       "  'got',\n",
       "  'first',\n",
       "  'good',\n",
       "  'job',\n",
       "  'field',\n",
       "  'and',\n",
       "  'never',\n",
       "  'really',\n",
       "  'felt',\n",
       "  'more',\n",
       "  'out',\n",
       "  'place',\n",
       "  'than',\n",
       "  'here'],\n",
       " ['want', 'fit', 'everybody', 'nice', 'professional', 'and', 'scholarly'],\n",
       " ['all',\n",
       "  'know',\n",
       "  'how',\n",
       "  'memorize',\n",
       "  'information',\n",
       "  'and',\n",
       "  'regurgitate',\n",
       "  'test',\n",
       "  'and',\n",
       "  'somehow',\n",
       "  'well'],\n",
       " ['just', 'feels', 'weird'],\n",
       " ['maybe', 'confidence', 'thing'],\n",
       " ['know',\n",
       "  'can',\n",
       "  'whatever',\n",
       "  'needed',\n",
       "  'done',\n",
       "  'just',\n",
       "  'don',\n",
       "  'know',\n",
       "  'have',\n",
       "  'any',\n",
       "  'thing',\n",
       "  'new',\n",
       "  'offer',\n",
       "  'worthwhile',\n",
       "  'contribute']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the document in differnt parts(sentences, words) and lemmatize. \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import gensim \n",
    "\n",
    "#Split the doucment into sentences. \n",
    "nltk.download('punkt')\n",
    "list_of_sentences = sent_tokenize(corpus)\n",
    "list_of_sentences\n",
    "\n",
    "#Deaccent and remove some basic stopwords with gensim. \n",
    "list_of_sentences_data = []\n",
    "for i in list_of_sentences:\n",
    "  list_of_sentences_data.append(gensim.utils.simple_preprocess(i, deacc= True, min_len = 3))\n",
    "\n",
    "#Remove any numbers, but not words that contain numbers in them. \n",
    "list_of_sentences_data = [[token for token in data if not token.isnumeric()]for data in list_of_sentences_data]\n",
    "\n",
    "#Remove words that contain only one charcter. \n",
    "list_of_sentences_data = [[token for token in data if len(token) > 1]for data in list_of_sentences_data]\n",
    "\n",
    "list_of_sentences_data \n",
    "\n",
    "##Split the document into tokens. #Alternative \n",
    "\n",
    "#from nltk.tokenize.regexp import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#for i in range(len(list_of_sentences_data)):\n",
    "    #list_of_sentences_data[i] = list_of_sentences_data[i].lower() # Convert into lowercase. \n",
    "    #list_of_sentences_data[i] = tokenizer.tokenize(list_of_sentences_data[i]) #Split into words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#from gensim.utilis import lemmatize ##lemmatize for V3 \n",
    "import re\n",
    "\n",
    "#adding bigrams to docs for chratcter that only appear 20 times or more. \n",
    "bigram = Phrases(list_of_sentences_data, min_count=20)\n",
    "bigram \n",
    "\n",
    "#In case prompted to install 'stopwords', use \"nltk.download('stopwords')\".\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Lemmatize the documents.#Alternative\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Funtion to lemmatize, apply bigrams and tokenize the given data set.\n",
    "def process_texts(texts):\n",
    "   texts = [[word for word in line if word not in stops] for line in texts] #tokenize the do\n",
    "   texts = [bigram[line] for line in texts]\n",
    "   texts = [[lemmatizer.lemmatize(token) for token in doc] for doc in texts]\n",
    "   #texts = [word.encode(\"utf-8\").split('/')[0] for word in texts]\n",
    "   return texts\n",
    "    # lemmatize the document(Other methods can be used to execute this. This method is best when working on collab or with gensim V3,gensim.utils has been dropped for V4)\n",
    "    # texts = [[word.decode(\"utf-8\").split('/')[0] for word in lemmatize(' '.join(line), allowed_tags=re.compile('(NN)'), min_length=5)] for line in texts]\n",
    "  \n",
    "     #trigrams_ = [t for t in trigram[bigram[sent]] if t.count(' ') == 2]\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "id": "YBbn1X-MCLQR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pattern in c:\\program files\\python310\\lib\\site-packages (3.6)\n",
      "Requirement already satisfied: cherrypy in c:\\program files\\python310\\lib\\site-packages (from pattern) (18.6.1)\n",
      "Requirement already satisfied: feedparser in c:\\program files\\python310\\lib\\site-packages (from pattern) (6.0.10)\n",
      "Requirement already satisfied: scipy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (1.8.1)\n",
      "Requirement already satisfied: python-docx in c:\\program files\\python310\\lib\\site-packages (from pattern) (0.8.11)\n",
      "Requirement already satisfied: lxml in c:\\program files\\python310\\lib\\site-packages (from pattern) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (4.11.1)\n",
      "Requirement already satisfied: pdfminer.six in c:\\program files\\python310\\lib\\site-packages (from pattern) (20220524)\n",
      "Requirement already satisfied: backports.csv in c:\\program files\\python310\\lib\\site-packages (from pattern) (1.0.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (1.22.3)\n",
      "Requirement already satisfied: requests in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (2.27.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (3.7)\n",
      "Requirement already satisfied: future in c:\\program files\\python310\\lib\\site-packages (from pattern) (0.18.2)\n",
      "Requirement already satisfied: mysqlclient in c:\\program files\\python310\\lib\\site-packages (from pattern) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4->pattern) (2.3.2.post1)\n",
      "Requirement already satisfied: jaraco.collections in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (3.5.1)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (3.1.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (8.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (8.13.0)\n",
      "Requirement already satisfied: zc.lockfile in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (2.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\program files\\python310\\lib\\site-packages (from feedparser->pattern) (1.0.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pdfminer.six->pattern) (2.0.12)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\program files\\python310\\lib\\site-packages (from pdfminer.six->pattern) (36.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (1.26.8)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.16.0)\n",
      "Requirement already satisfied: jaraco.functools in c:\\program files\\python310\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\program files\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.0)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\program files\\python310\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern) (5.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->pattern) (0.4.4)\n",
      "Requirement already satisfied: jaraco.classes in c:\\program files\\python310\\lib\\site-packages (from jaraco.collections->cherrypy->pattern) (3.2.1)\n",
      "Requirement already satisfied: jaraco.text in c:\\program files\\python310\\lib\\site-packages (from jaraco.collections->cherrypy->pattern) (3.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from zc.lockfile->cherrypy->pattern) (62.6.0)\n",
      "Requirement already satisfied: pycparser in c:\\program files\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
      "Requirement already satisfied: pytz in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.1)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in c:\\program files\\python310\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "id": "feTaBeJ9JgXZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young',\n",
       "  'first',\n",
       "  'gen',\n",
       "  'college',\n",
       "  'graduate',\n",
       "  'dad',\n",
       "  'joined',\n",
       "  'military',\n",
       "  'soon',\n",
       "  'could',\n",
       "  'mom',\n",
       "  'dropped'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'understood',\n",
       "  'different',\n",
       "  'started',\n",
       "  'hanging',\n",
       "  'people',\n",
       "  'major',\n",
       "  'marine',\n",
       "  'science'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'missed',\n",
       "  'crucial',\n",
       "  'stage',\n",
       "  'growing',\n",
       "  'interest',\n",
       "  'would',\n",
       "  'nurtured'],\n",
       " ['study', 'independently'],\n",
       " ['hated',\n",
       "  'teacher',\n",
       "  'high',\n",
       "  'school',\n",
       "  'seemed',\n",
       "  'provide',\n",
       "  'helping',\n",
       "  'hand',\n",
       "  'kid',\n",
       "  'needed',\n",
       "  'least'],\n",
       " ['grew',\n",
       "  'bit',\n",
       "  'unhealthy',\n",
       "  'resentment',\n",
       "  'preppy',\n",
       "  'kid',\n",
       "  'angst',\n",
       "  'ridden',\n",
       "  'phase'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'thought',\n",
       "  'going',\n",
       "  'college',\n",
       "  'talked',\n",
       "  'even',\n",
       "  'sibling'],\n",
       " ['kind', 'wound', 'le', 'ended', 'winging'],\n",
       " ['fast',\n",
       "  'forward',\n",
       "  'year',\n",
       "  'succeeding',\n",
       "  'best',\n",
       "  'class',\n",
       "  'still',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'missing',\n",
       "  'something',\n",
       "  'despite',\n",
       "  'usually',\n",
       "  'near',\n",
       "  'top',\n",
       "  'class',\n",
       "  'climate',\n",
       "  'change',\n",
       "  'research',\n",
       "  'undergraduate',\n",
       "  'leading',\n",
       "  'study',\n",
       "  'session',\n",
       "  'people',\n",
       "  'honor',\n",
       "  'college',\n",
       "  'university',\n",
       "  'many',\n",
       "  'intelligent',\n",
       "  'motivating',\n",
       "  'friend',\n",
       "  'winning',\n",
       "  'prestigious',\n",
       "  'scholarship'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'got',\n",
       "  'concept',\n",
       "  'class',\n",
       "  'everybody',\n",
       "  'else',\n",
       "  'seemed',\n",
       "  'understand',\n",
       "  'networking',\n",
       "  'scholarship',\n",
       "  'opportunity',\n",
       "  'aspect',\n",
       "  'college'],\n",
       " ['graduated',\n",
       "  'big',\n",
       "  'school',\n",
       "  'degree',\n",
       "  'peer',\n",
       "  'thought',\n",
       "  'highly',\n",
       "  'always',\n",
       "  'felt',\n",
       "  'le',\n",
       "  'everyone',\n",
       "  'else'],\n",
       " ['felt', 'like', 'everyone', 'else', 'plan', 'knew'],\n",
       " ['fast', 'forward'],\n",
       " ['finally',\n",
       "  'got',\n",
       "  'first',\n",
       "  'good',\n",
       "  'job',\n",
       "  'field',\n",
       "  'never',\n",
       "  'really',\n",
       "  'felt',\n",
       "  'place'],\n",
       " ['want', 'fit', 'everybody', 'nice', 'professional', 'scholarly'],\n",
       " ['know', 'memorize', 'information', 'regurgitate', 'test', 'somehow', 'well'],\n",
       " ['feel', 'weird'],\n",
       " ['maybe', 'confidence', 'thing'],\n",
       " ['know',\n",
       "  'whatever',\n",
       "  'needed',\n",
       "  'done',\n",
       "  'know',\n",
       "  'thing',\n",
       "  'new',\n",
       "  'offer',\n",
       "  'worthwhile',\n",
       "  'contribute']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = process_texts(list_of_sentences_data)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x2dc44571900>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<1 unique tokens: ['felt']>\n",
      "Number of documents: 19\n"
     ]
    }
   ],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(train_texts)\n",
    "dictionary\n",
    "\n",
    "# Filter out words that occur more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_above=0.5)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(text) for text in train_texts]\n",
    "\n",
    "#See how mnay tokens and documents we have to train on. \n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "#print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "Edw7Y3MIJnLK"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim.models.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LdaModel\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LdaMallet \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim.models.wrappers'"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet \n",
    "from gensim.corpora import Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfZ4kT02PHtg"
   },
   "outputs": [],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlSQdZy4R7aO"
   },
   "outputs": [],
   "source": [
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cskTzFfzR-Kp"
   },
   "outputs": [],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "id": "vhwBJnIhT9VZ",
    "outputId": "607d7393-24e0-42c4-ba97-9a7d0bbf94e1"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demo V1.1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
