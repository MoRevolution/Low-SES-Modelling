{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LTbCG8EWzT9o"
   },
   "outputs": [],
   "source": [
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Y5Ufxnp1z_hP"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vDJXBjEn1DmM"
   },
   "outputs": [],
   "source": [
    "corpus = \"So Im a young first gen college graduate, my dad joined the military as soon as he could and my mom dropped out at 16. I never really understood how different I was until I started hanging out with people in the same major as me (Marine Science). I always felt like I missed a crucial stage growing up where my interests wouldve been nurtured. Most of my studies I just did independently. I hated my teachers in high school because they only seemed to provide their helping hands to the kids who needed it least. I grew a bit of an unhealthy resentment to the preppy kids in my angst-ridden phase. I never really thought of going to college, it wasnt talked about, even with my other siblings. I just kind of wound up there and more or less, ended up winging it. Fast forward a few years and I am succeeding as best I can in classes and still feel like Im missing something despite usually being near the top of most of my classes, doing climate change research as an undergraduate, leading study sessions with people in the honors college at my university and having many intelligent and motivating friends winning prestigious scholarships. I always felt like I got the concepts of the classes but everybody else seemed to understand the networking and scholarship and opportunity aspects of college. I graduated from a big school with my degree, my peers thought very highly of me, but I always felt less than everyone else. I felt like everyone else had a plan, knew what they were doing. So fast forward some more and here I am. I finally got my first good job in my field and I never really felt more out of place than here. I want to fit in, everybody is so nice, professional and scholarly. All I know how to do is memorize information and regurgitate it on a test and somehow do well. It just feels weird. Maybe its a confidence thing? I know I can do whatever is needed to be done, I just dont know if I have any thing new to offer or worthwhile to contribute.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UVH_sANW2MOp"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZMrmy_tMyt8",
    "outputId": "35861dd3-11de-4ca1-af86-95d9839baf3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(punkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MFyKGQ-x3IZV"
   },
   "outputs": [],
   "source": [
    "list_of_sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "s3-mi8fT3QAr",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"So Im a young first gen college graduate, my dad joined the military as soon as he could and my mom dropped out at 16.\",\n",
       " I never really understood how different I was until I started hanging out with people in the same major as me (Marine Science).,\n",
       " \"I always felt like I missed a crucial stage growing up where my interests wouldve been nurtured.\",\n",
       " Most of my studies I just did independently.,\n",
       " I hated my teachers in high school because they only seemed to provide their helping hands to the kids who needed it least.,\n",
       " I grew a bit of an unhealthy resentment to the preppy kids in my angst-ridden phase.,\n",
       " \"I never really thought of going to college, it wasnt talked about, even with my other siblings.\",\n",
       " I just kind of wound up there and more or less, ended up winging it.,\n",
       " \"Fast forward a few years and I am succeeding as best I can in classes and still feel like Im missing something despite usually being near the top of most of my classes, doing climate change research as an undergraduate, leading study sessions with people in the honors college at my university and having many intelligent and motivating friends winning prestigious scholarships.\",\n",
       " I always felt like I got the concepts of the classes but everybody else seemed to understand the networking and scholarship and opportunity aspects of college.,\n",
       " I graduated from a big school with my degree, my peers thought very highly of me, but I always felt less than everyone else.,\n",
       " I felt like everyone else had a plan, knew what they were doing.,\n",
       " So fast forward some more and here I am.,\n",
       " I finally got my first good job in my field and I never really felt more out of place than here.,\n",
       " I want to fit in, everybody is so nice, professional and scholarly.,\n",
       " All I know how to do is memorize information and regurgitate it on a test and somehow do well.,\n",
       " It just feels weird.,\n",
       " \"Maybe its a confidence thing?\",\n",
       " \"I know I can do whatever is needed to be done, I just dont know if I have any thing new to offer or worthwhile to contribute.\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "r1jwWr296IVD"
   },
   "outputs": [],
   "source": [
    "list_of_sentences_data = []\n",
    "for i in list_of_sentences:\n",
    "  list_of_sentences_data.append(gensim.utils.simple_preprocess(i, deacc= True, min_len = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UZ5BaFoe6omz"
   },
   "outputs": [],
   "source": [
    "texts = list_of_sentences_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "id": "yyoznE7e60Q6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[young,\n",
       "  first,\n",
       "  gen,\n",
       "  college,\n",
       "  graduate,\n",
       "  dad,\n",
       "  joined,\n",
       "  the,\n",
       "  military,\n",
       "  soon,\n",
       "  could,\n",
       "  and,\n",
       "  mom,\n",
       "  dropped,\n",
       "  out],\n",
       " [never,\n",
       "  really,\n",
       "  understood,\n",
       "  how,\n",
       "  different,\n",
       "  was,\n",
       "  until,\n",
       "  started,\n",
       "  hanging,\n",
       "  out,\n",
       "  with,\n",
       "  people,\n",
       "  the,\n",
       "  same,\n",
       "  major,\n",
       "  marine,\n",
       "  science],\n",
       " [always,\n",
       "  felt,\n",
       "  like,\n",
       "  missed,\n",
       "  crucial,\n",
       "  stage,\n",
       "  growing,\n",
       "  where,\n",
       "  interests,\n",
       "  would,\n",
       "  been,\n",
       "  nurtured],\n",
       " [most, studies, just, did, independently],\n",
       " [hated,\n",
       "  teachers,\n",
       "  high,\n",
       "  school,\n",
       "  because,\n",
       "  they,\n",
       "  only,\n",
       "  seemed,\n",
       "  provide,\n",
       "  their,\n",
       "  helping,\n",
       "  hands,\n",
       "  the,\n",
       "  kids,\n",
       "  who,\n",
       "  needed,\n",
       "  least],\n",
       " [grew,\n",
       "  bit,\n",
       "  unhealthy,\n",
       "  resentment,\n",
       "  the,\n",
       "  preppy,\n",
       "  kids,\n",
       "  angst,\n",
       "  ridden,\n",
       "  phase],\n",
       " [never,\n",
       "  really,\n",
       "  thought,\n",
       "  going,\n",
       "  college,\n",
       "  wasn,\n",
       "  talked,\n",
       "  about,\n",
       "  even,\n",
       "  with,\n",
       "  other,\n",
       "  siblings],\n",
       " [just, kind, wound, there, and, more, less, ended, winging],\n",
       " [fast,\n",
       "  forward,\n",
       "  few,\n",
       "  years,\n",
       "  and,\n",
       "  succeeding,\n",
       "  best,\n",
       "  can,\n",
       "  classes,\n",
       "  and,\n",
       "  still,\n",
       "  feel,\n",
       "  like,\n",
       "  missing,\n",
       "  something,\n",
       "  despite,\n",
       "  usually,\n",
       "  being,\n",
       "  near,\n",
       "  the,\n",
       "  top,\n",
       "  most,\n",
       "  classes,\n",
       "  doing,\n",
       "  climate,\n",
       "  change,\n",
       "  research,\n",
       "  undergraduate,\n",
       "  leading,\n",
       "  study,\n",
       "  sessions,\n",
       "  with,\n",
       "  people,\n",
       "  the,\n",
       "  honors,\n",
       "  college,\n",
       "  university,\n",
       "  and,\n",
       "  having,\n",
       "  many,\n",
       "  intelligent,\n",
       "  and,\n",
       "  motivating,\n",
       "  friends,\n",
       "  winning,\n",
       "  prestigious,\n",
       "  scholarships],\n",
       " [always,\n",
       "  felt,\n",
       "  like,\n",
       "  got,\n",
       "  the,\n",
       "  concepts,\n",
       "  the,\n",
       "  classes,\n",
       "  but,\n",
       "  everybody,\n",
       "  else,\n",
       "  seemed,\n",
       "  understand,\n",
       "  the,\n",
       "  networking,\n",
       "  and,\n",
       "  scholarship,\n",
       "  and,\n",
       "  opportunity,\n",
       "  aspects,\n",
       "  college],\n",
       " [graduated,\n",
       "  from,\n",
       "  big,\n",
       "  school,\n",
       "  with,\n",
       "  degree,\n",
       "  peers,\n",
       "  thought,\n",
       "  very,\n",
       "  highly,\n",
       "  but,\n",
       "  always,\n",
       "  felt,\n",
       "  less,\n",
       "  than,\n",
       "  everyone,\n",
       "  else],\n",
       " [felt,\n",
       "  like,\n",
       "  everyone,\n",
       "  else,\n",
       "  had,\n",
       "  plan,\n",
       "  knew,\n",
       "  what,\n",
       "  they,\n",
       "  were,\n",
       "  doing],\n",
       " [fast, forward, some, more, and, here],\n",
       " [finally,\n",
       "  got,\n",
       "  first,\n",
       "  good,\n",
       "  job,\n",
       "  field,\n",
       "  and,\n",
       "  never,\n",
       "  really,\n",
       "  felt,\n",
       "  more,\n",
       "  out,\n",
       "  place,\n",
       "  than,\n",
       "  here],\n",
       " [want, fit, everybody, nice, professional, and, scholarly],\n",
       " [all,\n",
       "  know,\n",
       "  how,\n",
       "  memorize,\n",
       "  information,\n",
       "  and,\n",
       "  regurgitate,\n",
       "  test,\n",
       "  and,\n",
       "  somehow,\n",
       "  well],\n",
       " [just, feels, weird],\n",
       " [maybe, confidence, thing],\n",
       " [know,\n",
       "  can,\n",
       "  whatever,\n",
       "  needed,\n",
       "  done,\n",
       "  just,\n",
       "  don,\n",
       "  know,\n",
       "  have,\n",
       "  any,\n",
       "  thing,\n",
       "  new,\n",
       "  offer,\n",
       "  worthwhile,\n",
       "  contribute]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-LEhB_Sg7HNY"
   },
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(list_of_sentences_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soHWytyZ8FGc",
    "outputId": "8139626a-592c-4cdb-9bbb-d83100f5c1eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.phrases.Phrases at 0x1dd3e234dc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oTwXJtf280w1"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name lemmatize from gensim.utils (C:\\Users\\MoRevolution\\AppData\\Roaming\\Python\\Python310\\site-packages\\gensim\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lemmatize\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name lemmatize from gensim.utils (C:\\Users\\MoRevolution\\AppData\\Roaming\\Python\\Python310\\site-packages\\gensim\\utils.py)"
     ]
    }
   ],
   "source": [
    "from gensim.utils import lemmatize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOyGdx5y_SU7"
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E65lI9i89KPX"
   },
   "outputs": [],
   "source": [
    "def process_texts(texts): \n",
    "   texts = [[word for word in line if word not in stops] for line in texts] \n",
    "   texts = [bigram[line] for line in texts]\n",
    "   texts = [[word.decode(\"utf-8\").split(/)[0] for word in lemmatize( .join(line), allowed_tags=re.compile((NN)), min_length=5)] for line in texts]\n",
    "   #trigrams_ = [t for t in trigram[bigram[sent]] if t.count( ) == 2]\n",
    "   return texts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBbn1X-MCLQR"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feTaBeJ9JgXZ"
   },
   "outputs": [],
   "source": [
    "train_texts = process_texts(list_of_sentences_data)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Edw7Y3MIJnLK"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet \n",
    "from gensim.corpora import Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MqVSKg6KlGJ"
   },
   "outputs": [],
   "source": [
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xe2xzAbuKLbi"
   },
   "outputs": [],
   "source": [
    "dictionary = Dictionary(train_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in train_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZ6dP6kiKXca",
    "outputId": "65685bdc-8798-45f2-a75b-f8e003ed2822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(41 unique tokens: [college, graduate, marine, person, science]...)\n"
     ]
    }
   ],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zf5LXoryKYfN",
    "outputId": "2dbd5d77-71d5-4499-b0a8-f9b1cc9713e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1)], [(2, 1), (3, 1), (4, 1)], [(5, 1), (6, 1)], [(7, 1)], [(8, 1), (9, 1), (10, 1)], [(11, 1), (12, 1), (13, 1)], [(0, 1), (14, 1)], [], [(0, 1), (3, 1), (7, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)], [(0, 1), (16, 1), (21, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)], [(9, 1), (31, 1), (32, 1)], [(32, 1)], [], [(33, 1), (34, 1)], [(28, 1)], [(35, 1), (36, 1)], [], [(37, 1), (38, 1)], [(38, 1), (39, 1), (40, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xfZ4kT02PHtg",
    "outputId": "3cd531df-d77c-4985-d51b-bbd16378d728"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
      "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
     ]
    }
   ],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlSQdZy4R7aO",
    "outputId": "fc6a74e3-4192-44c4-fe06-5dee9965cf6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  0.100*\"class\" + 0.100*\"study\" + 0.052*\"college\" + 0.052*\"university\" + 0.052*\"change\" + 0.052*\"undergraduate\" + 0.052*\"person\" + 0.052*\"friend\" + 0.052*\"something\" + 0.052*\"scholarship\"),\n",
       " (1,\n",
       "  0.180*\"college\" + 0.180*\"graduate\" + 0.016*\"everybody\" + 0.016*\"thing\" + 0.016*\"everyone\" + 0.016*\"study\" + 0.016*\"interest\" + 0.016*\"stage\" + 0.016*\"regurgitate\" + 0.016*\"field\"),\n",
       " (2,\n",
       "  0.180*\"sibling\" + 0.180*\"college\" + 0.016*\"everyone\" + 0.016*\"everybody\" + 0.016*\"study\" + 0.016*\"thing\" + 0.016*\"stage\" + 0.016*\"field\" + 0.016*\"school\" + 0.016*\"regurgitate\"),\n",
       " (3,\n",
       "  0.136*\"resentment\" + 0.136*\"phase\" + 0.136*\"angst\" + 0.136*\"everyone\" + 0.012*\"everybody\" + 0.012*\"study\" + 0.012*\"college\" + 0.012*\"thing\" + 0.012*\"school\" + 0.012*\"stage\"),\n",
       " (4,\n",
       "  0.121*\"marine\" + 0.121*\"person\" + 0.121*\"science\" + 0.121*\"interest\" + 0.121*\"stage\" + 0.011*\"everyone\" + 0.011*\"college\" + 0.011*\"everybody\" + 0.011*\"thing\" + 0.011*\"study\"),\n",
       " (5,\n",
       "  0.136*\"information\" + 0.136*\"place\" + 0.136*\"field\" + 0.136*\"regurgitate\" + 0.012*\"everybody\" + 0.012*\"everyone\" + 0.012*\"thing\" + 0.012*\"college\" + 0.012*\"study\" + 0.012*\"school\"),\n",
       " (6,\n",
       "  0.121*\"everyone\" + 0.121*\"degree\" + 0.121*\"school\" + 0.121*\"confidence\" + 0.121*\"thing\" + 0.011*\"college\" + 0.011*\"everybody\" + 0.011*\"study\" + 0.011*\"regurgitate\" + 0.011*\"stage\"),\n",
       " (7,\n",
       "  0.024*\"everyone\" + 0.024*\"everybody\" + 0.024*\"college\" + 0.024*\"study\" + 0.024*\"thing\" + 0.024*\"contribute\" + 0.024*\"graduate\" + 0.024*\"place\" + 0.024*\"teacher\" + 0.024*\"regurgitate\"),\n",
       " (8,\n",
       "  0.073*\"college\" + 0.073*\"everybody\" + 0.073*\"opportunity\" + 0.073*\"scholarship\" + 0.073*\"concept\" + 0.073*\"networking\" + 0.073*\"aspect\" + 0.073*\"class\" + 0.073*\"school\" + 0.073*\"provide\"),\n",
       " (9,\n",
       "  0.155*\"thing\" + 0.155*\"offer\" + 0.155*\"contribute\" + 0.014*\"everyone\" + 0.014*\"college\" + 0.014*\"everybody\" + 0.014*\"study\" + 0.014*\"interest\" + 0.014*\"school\" + 0.014*\"stage\")]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cskTzFfzR-Kp",
    "outputId": "d21deb87-f38e-49be-cbaa-c083cbe140c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
      "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
      "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 916
    },
    "id": "vhwBJnIhT9VZ",
    "outputId": "0f004fb1-c787-49c4-a4ce-2d98522cf115"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument labels will be keyword-only\n",
      "  by=saliency, ascending=False).head(R).drop(saliency, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el581405338022714408322188619\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el581405338022714408322188619_data = {\"mdsDat\": {\"x\": [-0.16250950814607018, -0.11022631784482277, 0.10368942504409386, 0.032191080821736856, 0.08928769796789629, 0.054692071793755584, 0.061556435033029884, -0.033322051611863295, -0.03332175638716458, -0.002037076670591794], \"y\": [-0.049578363799659624, 0.11494552306378687, 0.08914982344638818, -0.13816148665159167, 0.019626856292629932, -0.04829325936714511, 0.01498537022130102, 0.0035539237884637405, 0.003552798240484277, -0.009781185234657826], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [29.566326042804047, 20.695677734062414, 8.850903054047448, 8.850893330512978, 7.278552093746248, 7.1213314275924, 6.335185374598211, 4.605624386306655, 4.605621757516998, 2.0898847988125997]}, \"tinfo\": {\"Term\": [\"college\", \"thing\", \"everyone\", \"sibling\", \"graduate\", \"offer\", \"contribute\", \"school\", \"resentment\", \"phase\", \"angst\", \"information\", \"place\", \"field\", \"regurgitate\", \"person\", \"degree\", \"marine\", \"science\", \"confidence\", \"interest\", \"stage\", \"study\", \"concept\", \"opportunity\", \"networking\", \"aspect\", \"teacher\", \"provide\", \"change\", \"study\", \"university\", \"change\", \"undergraduate\", \"friend\", \"something\", \"climate\", \"research\", \"session\", \"honor\", \"class\", \"person\", \"scholarship\", \"everybody\", \"college\", \"graduate\", \"sibling\", \"regurgitate\", \"place\", \"field\", \"information\", \"contribute\", \"offer\", \"phase\", \"angst\", \"resentment\", \"stage\", \"confidence\", \"interest\", \"science\", \"everyone\", \"thing\", \"school\", \"teacher\", \"opportunity\", \"concept\", \"networking\", \"aspect\", \"provide\", \"teacher\", \"school\", \"everybody\", \"scholarship\", \"class\", \"college\", \"sibling\", \"graduate\", \"regurgitate\", \"field\", \"information\", \"place\", \"contribute\", \"offer\", \"angst\", \"phase\", \"resentment\", \"interest\", \"stage\", \"confidence\", \"marine\", \"degree\", \"science\", \"session\", \"research\", \"everyone\", \"study\", \"thing\", \"person\", \"degree\", \"confidence\", \"thing\", \"everyone\", \"school\", \"graduate\", \"sibling\", \"regurgitate\", \"place\", \"field\", \"information\", \"contribute\", \"offer\", \"phase\", \"resentment\", \"angst\", \"stage\", \"interest\", \"science\", \"marine\", \"teacher\", \"provide\", \"aspect\", \"concept\", \"networking\", \"opportunity\", \"research\", \"honor\", \"session\", \"climate\", \"college\", \"everybody\", \"study\", \"person\", \"class\", \"scholarship\", \"marine\", \"science\", \"interest\", \"stage\", \"person\", \"graduate\", \"sibling\", \"regurgitate\", \"field\", \"information\", \"place\", \"contribute\", \"offer\", \"phase\", \"resentment\", \"angst\", \"confidence\", \"degree\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"honor\", \"research\", \"session\", \"climate\", \"change\", \"something\", \"undergraduate\", \"everyone\", \"college\", \"everybody\", \"thing\", \"study\", \"school\", \"class\", \"scholarship\", \"resentment\", \"phase\", \"angst\", \"everyone\", \"graduate\", \"sibling\", \"regurgitate\", \"field\", \"place\", \"information\", \"contribute\", \"offer\", \"stage\", \"interest\", \"confidence\", \"science\", \"marine\", \"degree\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"honor\", \"research\", \"session\", \"undergraduate\", \"something\", \"friend\", \"everybody\", \"study\", \"college\", \"thing\", \"school\", \"person\", \"class\", \"scholarship\", \"information\", \"place\", \"field\", \"regurgitate\", \"graduate\", \"sibling\", \"contribute\", \"offer\", \"angst\", \"phase\", \"resentment\", \"stage\", \"interest\", \"confidence\", \"science\", \"degree\", \"marine\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"research\", \"honor\", \"something\", \"undergraduate\", \"friend\", \"session\", \"climate\", \"everybody\", \"everyone\", \"thing\", \"college\", \"study\", \"school\", \"person\", \"class\", \"scholarship\", \"offer\", \"contribute\", \"thing\", \"graduate\", \"sibling\", \"field\", \"regurgitate\", \"place\", \"information\", \"angst\", \"resentment\", \"phase\", \"interest\", \"stage\", \"science\", \"confidence\", \"marine\", \"degree\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"honor\", \"climate\", \"session\", \"friend\", \"change\", \"undergraduate\", \"everyone\", \"college\", \"everybody\", \"study\", \"school\", \"person\", \"class\", \"scholarship\", \"sibling\", \"college\", \"graduate\", \"field\", \"regurgitate\", \"place\", \"information\", \"contribute\", \"offer\", \"angst\", \"phase\", \"resentment\", \"stage\", \"interest\", \"science\", \"confidence\", \"marine\", \"degree\", \"teacher\", \"provide\", \"networking\", \"aspect\", \"concept\", \"opportunity\", \"session\", \"honor\", \"university\", \"something\", \"change\", \"climate\", \"everyone\", \"everybody\", \"study\", \"thing\", \"school\", \"person\", \"class\", \"scholarship\", \"graduate\", \"college\", \"sibling\", \"field\", \"regurgitate\", \"place\", \"information\", \"contribute\", \"offer\", \"angst\", \"resentment\", \"phase\", \"interest\", \"stage\", \"confidence\", \"marine\", \"science\", \"degree\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"climate\", \"honor\", \"friend\", \"something\", \"change\", \"research\", \"everybody\", \"thing\", \"everyone\", \"study\", \"school\", \"person\", \"class\", \"scholarship\", \"graduate\", \"sibling\", \"place\", \"regurgitate\", \"field\", \"information\", \"contribute\", \"offer\", \"resentment\", \"angst\", \"phase\", \"interest\", \"confidence\", \"stage\", \"marine\", \"degree\", \"science\", \"teacher\", \"provide\", \"aspect\", \"networking\", \"concept\", \"opportunity\", \"honor\", \"session\", \"change\", \"research\", \"friend\", \"climate\", \"university\", \"everyone\", \"everybody\", \"college\", \"study\", \"thing\", \"school\", \"person\", \"class\", \"scholarship\"], \"Freq\": [2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5594095715548812, 0.8169355733054589, 0.8169350479226248, 0.8169348144191431, 0.8169341139086976, 0.8169333550223817, 0.8169325377601955, 0.8169315453703978, 0.816931311866916, 0.816930144349507, 1.559609800790525, 0.8169347560432726, 0.8169332382706409, 0.8166866002179894, 0.8169705404518585, 0.07427871993883546, 0.07427684461399725, 0.07428263841913942, 0.07428077768826882, 0.07427847913836985, 0.07427685920796485, 0.07428050040288418, 0.07427571358150728, 0.07427688839590009, 0.07427651624972596, 0.07427404257221565, 0.0742811133495239, 0.07427989475322826, 0.07427542170215502, 0.07427442931235738, 0.07429852395288564, 0.07428098200381539, 0.07427832590170992, 0.0742777275490378, 0.7990298397190949, 0.7990259987261068, 0.7990234653051997, 0.7990214222238231, 0.7989901222171328, 0.7989656052406131, 0.79899894832868, 0.7990550104816552, 0.7990296762725848, 0.7990210953308029, 0.7990597504304491, 0.07265098285915864, 0.07265050784273856, 0.07265407301974082, 0.07265172858386111, 0.07265143744476493, 0.07265003282631849, 0.07265291357105957, 0.07264707035832235, 0.0726512484597376, 0.07264741768215638, 0.07264622758725449, 0.07265382274227218, 0.07265070193546934, 0.07265007879564947, 0.07265021670364238, 0.07264843922284471, 0.07264685072707436, 0.07264276456432106, 0.07264251428685242, 0.07267540278931303, 0.07267018782409913, 0.07265833795211457, 0.07264991534913934, 0.5670112670390259, 0.566985613360563, 0.5669625809707713, 0.5670184318947274, 0.5670070729771519, 0.05155803076147097, 0.051556222072287786, 0.05156033749550169, 0.0515570870975493, 0.05155691234497122, 0.05155558859419222, 0.05155603421326634, 0.05155525219547941, 0.05155607790141086, 0.051554745413002964, 0.05155460124212604, 0.05155937198750777, 0.05155711331043602, 0.051555335202954, 0.05155333428593493, 0.05155692982022903, 0.05155495074728221, 0.05155191005242353, 0.051551800832062226, 0.0515513377377303, 0.051551045027162005, 0.05155118919803893, 0.051551123665822145, 0.05155094017561516, 0.05155087464339837, 0.05157240416101848, 0.05157064789760872, 0.0515675285640899, 0.05155639682486587, 0.05155324254083143, 0.051552582849849156, 0.5670059258103555, 0.5670030948217005, 0.5669747150341974, 0.5669669210777771, 0.5670044578903122, 0.05155819256069493, 0.05155799159545091, 0.05156004493598763, 0.05155797848902195, 0.05155720520971345, 0.05155713530875901, 0.05155606495039412, 0.051553753850087904, 0.051554684406543906, 0.051554444122013016, 0.05155381938223269, 0.0515581401349791, 0.05155232524933151, 0.05155753287043739, 0.05155502954250646, 0.05155228156123498, 0.05155227282361568, 0.051551626239787096, 0.05155157818288092, 0.051551289841443845, 0.051551254890966625, 0.051551246153347316, 0.05155115003953496, 0.05155101023762608, 0.05155090538619442, 0.05155090975500407, 0.05157993612633585, 0.051568402468853025, 0.05156721852143717, 0.051563959389436344, 0.05156103228696911, 0.05156006678003589, 0.051554518391777104, 0.05155233398695081, 0.5238469421638934, 0.5238459074661574, 0.523837572401063, 0.5237321481984197, 0.04763310066469802, 0.04763097378601874, 0.04763439762956833, 0.047633388080735764, 0.047633362931832464, 0.047631174977245165, 0.047633352153731046, 0.04762958700363665, 0.04763598201047638, 0.047633955727410304, 0.04763294258587727, 0.04763162047210366, 0.04763083367070035, 0.04763076540939138, 0.04763188633193857, 0.04763146957868385, 0.0476278122096036, 0.04762774754099511, 0.04762777628259888, 0.047627600240275764, 0.047627521200865386, 0.04762741701255171, 0.047627258933730945, 0.04762730923153755, 0.04762726611913189, 0.04762714396731585, 0.047648269046089785, 0.04764194589325949, 0.047641036940040134, 0.0476388920978585, 0.047636632289261766, 0.0476303306926343, 0.047629335514603625, 0.047629098396372485, 0.5125160419145257, 0.5125063121282543, 0.5124999568343312, 0.5124918580526949, 0.046605145460557086, 0.04660296961601156, 0.04660402765996666, 0.046600062631457204, 0.046603605848423095, 0.046601440549166165, 0.046601190977336227, 0.04660466740747438, 0.04660329651995782, 0.046602270111868495, 0.04660196781359561, 0.04660156006243684, 0.046601060918776964, 0.046602393140235364, 0.046600424686365424, 0.0465991135554842, 0.04659912058567659, 0.0465989202251934, 0.046598730409998804, 0.04659832265884003, 0.04659827344749328, 0.04659800278508616, 0.046598009815278556, 0.04659798169450898, 0.04659791842277745, 0.04659792193787365, 0.046620696246129606, 0.04661476276375022, 0.046611050822166905, 0.046610509497352674, 0.046609693995035124, 0.04660705064269549, 0.04660381323909868, 0.046600157539054506, 0.046600048571072424, 0.5201497648234155, 0.520117393563188, 0.5201600715925142, 0.04729674397449524, 0.047295064746641476, 0.047297216159608683, 0.04729732560648928, 0.047295311783886254, 0.04729455190982952, 0.04729445809821758, 0.04729321665788621, 0.047292716329289185, 0.047298889133354984, 0.047298213689749, 0.04729494591859968, 0.047294827090557885, 0.0472945394016146, 0.04729289457135188, 0.04729577146078477, 0.04729445497116385, 0.047291759450847376, 0.04729157182762349, 0.047290836969996614, 0.047290824461781684, 0.047290636838557804, 0.04729066498204138, 0.047290646219719, 0.047290424198904064, 0.04729040230952795, 0.04729040856363541, 0.04731564076019413, 0.04731272321906273, 0.04730805452784174, 0.04730495874464764, 0.04729842632940273, 0.04729624364589821, 0.04729326669074591, 0.0472915624464623, 0.44011832818906343, 0.44010152365441235, 0.04002046303299524, 0.04002300008124613, 0.04002105864826561, 0.04001993107126522, 0.04001908084183346, 0.04002050849980977, 0.04001836246616386, 0.04001990833785795, 0.040019126308648, 0.04001886260112371, 0.040023091014875195, 0.040020613073483195, 0.0400201174852048, 0.04001994925799103, 0.04001744403651031, 0.04001736674292561, 0.04001825789249044, 0.04001837155952677, 0.0400167938610625, 0.04001650742013095, 0.04001640284645753, 0.04001610276548161, 0.04001594363163075, 0.040015802684505705, 0.04001577085773553, 0.040015729937602454, 0.04001569356415083, 0.040015548070344326, 0.04003471233266959, 0.040033989410318535, 0.04002808781779227, 0.040024550499621676, 0.040022168038540196, 0.040020972261318, 0.040017625903768436, 0.040016966634957726, 0.4401065829749956, 0.4401132029394129, 0.040018630612004835, 0.04002253620914391, 0.04002255439585934, 0.04002125404570594, 0.04002030833650346, 0.0400206402440601, 0.04001747575557489, 0.040020476563621205, 0.04001984002858108, 0.04001825323765962, 0.040024236667036826, 0.04002289994345255, 0.040019435374162714, 0.0400190034396712, 0.040017894050029826, 0.04001736208860344, 0.04001939445405299, 0.04001727115502628, 0.0400166937268113, 0.04001630725910837, 0.04001615721870605, 0.040015857137901414, 0.040015857137901414, 0.040015698004141384, 0.040015702550820244, 0.04001565253735281, 0.040015629803958515, 0.040015538870381354, 0.040029810895316806, 0.04002937896082529, 0.04002880607928917, 0.04002878789257375, 0.04002199060768094, 0.04002004008245083, 0.0400186669854357, 0.04001734844856686, 0.027017440838866397, 0.027016009020827837, 0.027016619709789528, 0.027016295797063224, 0.02701616169306826, 0.02701552624644596, 0.027018841709829197, 0.027013871609461917, 0.027015381826759072, 0.027015090924246914, 0.027014694801677168, 0.027016017273381373, 0.02701582540151165, 0.02701566241357931, 0.02701456895023574, 0.027014172827665994, 0.027013980955796275, 0.027016597015267305, 0.027014222342987212, 0.02701319696321032, 0.02701313300592041, 0.027013149511027484, 0.027012800840640575, 0.027012697683721366, 0.027012710062551674, 0.027012660547230456, 0.027012631663293075, 0.027012563579726402, 0.027012528506373874, 0.027012528506373874, 0.027027740025679786, 0.027024696896563248, 0.027023968608713665, 0.027021053394176944, 0.027019995004185903, 0.027016211208389478, 0.027015235343933804, 0.027013811778448776, 0.02701380352589524], \"Total\": [2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.983842847967525, 1.241237566161011, 1.2412371615736697, 1.24123752056657, 1.2412370221233284, 1.2412369339387872, 1.2412365656356699, 1.2412362432588573, 1.2412361652340191, 1.2412355334486964, 2.7103115214659934, 1.7567321613729239, 1.9676366594033528, 1.96754499414095, 2.7679740623711733, 0.8987249280503475, 0.8987240171114624, 0.9645405840003103, 0.9645378245916292, 0.9645373576143581, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 0.9748272070786089, 0.9748272975072519, 0.9748248939500659, 1.0140586248298848, 1.0140589768663888, 1.014058081183685, 1.0140602367594163, 1.4903261049232648, 1.48694979929331, 1.7404468931035484, 1.2249420957750867, 1.224964743677595, 1.2249630483382812, 1.2249622315910504, 1.2249615582508455, 1.2249515341872832, 1.2249420957750867, 1.7404468931035484, 1.96754499414095, 1.9676366594033528, 2.7103115214659934, 2.7679740623711733, 0.8987240171114624, 0.8987249280503475, 0.9645405840003103, 0.9645373576143581, 0.9645377746830189, 0.9645378245916292, 0.971460276968189, 0.971460914275107, 0.9748272975072519, 0.9748272070786089, 0.9748248939500659, 1.014058081183685, 1.0140586248298848, 1.0140589768663888, 1.0140613346388478, 1.014059969579295, 1.0140602367594163, 1.2412361652340191, 1.2412362432588573, 1.4903261049232648, 1.983842847967525, 1.48694979929331, 1.7567321613729239, 1.014059969579295, 1.0140589768663888, 1.48694979929331, 1.4903261049232648, 1.7404468931035484, 0.8987249280503475, 0.8987240171114624, 0.9645405840003103, 0.9645378245916292, 0.9645373576143581, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 0.9748272070786089, 0.9748248939500659, 0.9748272975072519, 1.0140586248298848, 1.014058081183685, 1.0140602367594163, 1.0140613346388478, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249630483382812, 1.2249622315910504, 1.224964743677595, 1.2412362432588573, 1.2412355334486964, 1.2412361652340191, 1.2412365656356699, 2.7679740623711733, 1.96754499414095, 1.983842847967525, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 1.0140613346388478, 1.0140602367594163, 1.014058081183685, 1.0140586248298848, 1.7567321613729239, 0.8987249280503475, 0.8987240171114624, 0.9645405840003103, 0.9645373576143581, 0.9645377746830189, 0.9645378245916292, 0.971460276968189, 0.971460914275107, 0.9748272070786089, 0.9748248939500659, 0.9748272975072519, 1.0140589768663888, 1.014059969579295, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412355334486964, 1.2412362432588573, 1.2412361652340191, 1.2412365656356699, 1.2412371615736697, 1.2412369339387872, 1.24123752056657, 1.4903261049232648, 2.7679740623711733, 1.96754499414095, 1.48694979929331, 1.983842847967525, 1.7404468931035484, 2.7103115214659934, 1.9676366594033528, 0.9748248939500659, 0.9748272070786089, 0.9748272975072519, 1.4903261049232648, 0.8987249280503475, 0.8987240171114624, 0.9645405840003103, 0.9645373576143581, 0.9645378245916292, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 1.0140586248298848, 1.014058081183685, 1.0140589768663888, 1.0140602367594163, 1.0140613346388478, 1.014059969579295, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412355334486964, 1.2412362432588573, 1.2412361652340191, 1.24123752056657, 1.2412369339387872, 1.2412370221233284, 1.96754499414095, 1.983842847967525, 2.7679740623711733, 1.48694979929331, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 0.9645377746830189, 0.9645378245916292, 0.9645373576143581, 0.9645405840003103, 0.8987249280503475, 0.8987240171114624, 0.971460276968189, 0.971460914275107, 0.9748272975072519, 0.9748272070786089, 0.9748248939500659, 1.0140586248298848, 1.014058081183685, 1.0140589768663888, 1.0140602367594163, 1.014059969579295, 1.0140613346388478, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412362432588573, 1.2412355334486964, 1.2412369339387872, 1.24123752056657, 1.2412370221233284, 1.2412361652340191, 1.2412365656356699, 1.96754499414095, 1.4903261049232648, 1.48694979929331, 2.7679740623711733, 1.983842847967525, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 0.971460914275107, 0.971460276968189, 1.48694979929331, 0.8987249280503475, 0.8987240171114624, 0.9645373576143581, 0.9645405840003103, 0.9645378245916292, 0.9645377746830189, 0.9748272975072519, 0.9748248939500659, 0.9748272070786089, 1.014058081183685, 1.0140586248298848, 1.0140602367594163, 1.0140589768663888, 1.0140613346388478, 1.014059969579295, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412355334486964, 1.2412365656356699, 1.2412361652340191, 1.2412370221233284, 1.2412371615736697, 1.24123752056657, 1.4903261049232648, 2.7679740623711733, 1.96754499414095, 1.983842847967525, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 0.8987240171114624, 2.7679740623711733, 0.8987249280503475, 0.9645373576143581, 0.9645405840003103, 0.9645378245916292, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 0.9748272975072519, 0.9748272070786089, 0.9748248939500659, 1.0140586248298848, 1.014058081183685, 1.0140602367594163, 1.0140589768663888, 1.0140613346388478, 1.014059969579295, 1.2249420957750867, 1.2249515341872832, 1.2249622315910504, 1.2249615582508455, 1.2249630483382812, 1.224964743677595, 1.2412361652340191, 1.2412355334486964, 1.241237566161011, 1.2412369339387872, 1.2412371615736697, 1.2412365656356699, 1.4903261049232648, 1.96754499414095, 1.983842847967525, 1.48694979929331, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 0.8987249280503475, 2.7679740623711733, 0.8987240171114624, 0.9645373576143581, 0.9645405840003103, 0.9645378245916292, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 0.9748272975072519, 0.9748248939500659, 0.9748272070786089, 1.014058081183685, 1.0140586248298848, 1.0140589768663888, 1.0140613346388478, 1.0140602367594163, 1.014059969579295, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412365656356699, 1.2412355334486964, 1.2412370221233284, 1.2412369339387872, 1.2412371615736697, 1.2412362432588573, 1.96754499414095, 1.48694979929331, 1.4903261049232648, 1.983842847967525, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528, 0.8987249280503475, 0.8987240171114624, 0.9645378245916292, 0.9645405840003103, 0.9645373576143581, 0.9645377746830189, 0.971460276968189, 0.971460914275107, 0.9748248939500659, 0.9748272975072519, 0.9748272070786089, 1.014058081183685, 1.0140589768663888, 1.0140586248298848, 1.0140613346388478, 1.014059969579295, 1.0140602367594163, 1.2249420957750867, 1.2249515341872832, 1.2249615582508455, 1.2249622315910504, 1.2249630483382812, 1.224964743677595, 1.2412355334486964, 1.2412361652340191, 1.2412371615736697, 1.2412362432588573, 1.2412370221233284, 1.2412365656356699, 1.241237566161011, 1.4903261049232648, 1.96754499414095, 2.7679740623711733, 1.983842847967525, 1.48694979929331, 1.7404468931035484, 1.7567321613729239, 2.7103115214659934, 1.9676366594033528], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.3075, -2.954, -2.954, -2.954, -2.954, -2.954, -2.954, -2.954, -2.954, -2.954, -2.3073, -2.954, -2.954, -2.9543, -2.9539, -5.3517, -5.3517, -5.3516, -5.3517, -5.3517, -5.3517, -5.3517, -5.3517, -5.3517, -5.3517, -5.3518, -5.3517, -5.3517, -5.3517, -5.3517, -5.3514, -5.3517, -5.3517, -5.3517, -2.6194, -2.6194, -2.6194, -2.6194, -2.6195, -2.6195, -2.6194, -2.6194, -2.6194, -2.6194, -2.6194, -5.0171, -5.0171, -5.0171, -5.0171, -5.0171, -5.0171, -5.0171, -5.0172, -5.0171, -5.0172, -5.0172, -5.0171, -5.0171, -5.0171, -5.0171, -5.0172, -5.0172, -5.0172, -5.0173, -5.0168, -5.0169, -5.017, -5.0171, -2.113, -2.1131, -2.1131, -2.113, -2.113, -4.5107, -4.5107, -4.5106, -4.5107, -4.5107, -4.5107, -4.5107, -4.5107, -4.5107, -4.5108, -4.5108, -4.5107, -4.5107, -4.5107, -4.5108, -4.5107, -4.5107, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5104, -4.5104, -4.5105, -4.5107, -4.5108, -4.5108, -2.113, -2.113, -2.1131, -2.1131, -2.113, -4.5107, -4.5107, -4.5106, -4.5107, -4.5107, -4.5107, -4.5107, -4.5108, -4.5108, -4.5108, -4.5108, -4.5107, -4.5108, -4.5107, -4.5107, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5108, -4.5103, -4.5105, -4.5105, -4.5106, -4.5106, -4.5106, -4.5108, -4.5108, -1.9966, -1.9966, -1.9966, -1.9968, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3944, -4.3942, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.394, -4.3941, -4.3941, -4.3942, -4.3942, -4.3943, -4.3944, -4.3944, -1.9966, -1.9967, -1.9967, -1.9967, -4.3943, -4.3943, -4.3943, -4.3944, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3943, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3944, -4.3939, -4.3941, -4.3941, -4.3941, -4.3942, -4.3942, -4.3943, -4.3944, -4.3944, -1.8649, -1.8649, -1.8649, -4.2626, -4.2626, -4.2625, -4.2625, -4.2626, -4.2626, -4.2626, -4.2626, -4.2626, -4.2625, -4.2625, -4.2626, -4.2626, -4.2626, -4.2626, -4.2626, -4.2626, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2627, -4.2622, -4.2622, -4.2623, -4.2624, -4.2625, -4.2626, -4.2626, -4.2627, -1.7131, -1.7131, -4.1108, -4.1107, -4.1107, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1107, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1104, -4.1104, -4.1106, -4.1107, -4.1107, -4.1108, -4.1108, -4.1109, -1.7131, -1.7131, -4.1108, -4.1107, -4.1107, -4.1107, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1107, -4.1107, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1108, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1109, -4.1105, -4.1105, -4.1106, -4.1106, -4.1107, -4.1108, -4.1108, -4.1108, -3.7135, -3.7136, -3.7135, -3.7135, -3.7136, -3.7136, -3.7135, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7136, -3.7135, -3.7136, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7137, -3.7131, -3.7132, -3.7133, -3.7134, -3.7134, -3.7135, -3.7136, -3.7136, -3.7136], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9778, 0.8002, 0.8002, 0.8002, 0.8002, 0.8002, 0.8002, 0.8002, 0.8002, 0.8002, 0.6659, 0.4529, 0.3395, 0.3392, -0.0017, -1.2746, -1.2746, -1.3452, -1.3453, -1.3453, -1.3453, -1.3524, -1.3525, -1.3559, -1.3559, -1.356, -1.3953, -1.3953, -1.3954, -1.3954, -1.7801, -1.7781, -1.9355, -1.5843, 1.148, 1.148, 1.148, 1.148, 1.1479, 1.1479, 0.7967, 0.6741, 0.6741, 0.3538, 0.3328, -0.9401, -0.9401, -1.0107, -1.0107, -1.0107, -1.0107, -1.0179, -1.0179, -1.0213, -1.0214, -1.0214, -1.0608, -1.0608, -1.0608, -1.0608, -1.0608, -1.0609, -1.2631, -1.2631, -1.4455, -1.7316, -1.4435, -1.6103, 1.8433, 1.8433, 1.4605, 1.4583, 1.3031, -0.4336, -0.4337, -0.5042, -0.5043, -0.5043, -0.5043, -0.5115, -0.5115, -0.5149, -0.515, -0.515, -0.5543, -0.5544, -0.5544, -0.5545, -0.7433, -0.7434, -0.7434, -0.7434, -0.7434, -0.7434, -0.7566, -0.7566, -0.7566, -0.7566, -1.5582, -1.2169, -1.2252, -1.1039, -1.5376, -1.2173, 1.8433, 1.8433, 1.8433, 1.8432, 1.2938, -0.4336, -0.4336, -0.5043, -0.5043, -0.5043, -0.5043, -0.5115, -0.5115, -0.515, -0.515, -0.515, -0.5544, -0.5545, -0.7433, -0.7434, -0.7434, -0.7434, -0.7434, -0.7434, -0.7566, -0.7566, -0.7566, -0.7566, -0.7566, -0.7566, -0.7566, -0.939, -1.5583, -1.217, -0.937, -1.2254, -1.0945, -1.5375, -1.2173, 1.9992, 1.9992, 1.9992, 1.5745, -0.3172, -0.3173, -0.3879, -0.3879, -0.3879, -0.3879, -0.395, -0.3951, -0.4379, -0.4379, -0.438, -0.438, -0.438, -0.438, -0.6269, -0.6269, -0.627, -0.627, -0.627, -0.627, -0.6402, -0.6402, -0.6402, -0.6402, -0.6402, -0.6402, -1.1005, -1.1088, -1.4419, -0.8206, -0.9781, -0.9875, -1.4211, -1.1009, 2.0098, 2.0097, 2.0097, 2.0097, -0.3172, -0.3172, -0.395, -0.3951, -0.3985, -0.3986, -0.3986, -0.4379, -0.438, -0.438, -0.438, -0.438, -0.438, -0.6269, -0.627, -0.627, -0.627, -0.627, -0.627, -0.6402, -0.6402, -0.6402, -0.6402, -0.6402, -0.6402, -0.6402, -1.1004, -0.8228, -0.8206, -1.442, -1.1089, -0.9781, -0.9875, -1.4211, -1.1009, 2.1344, 2.1343, 1.7087, -0.1855, -0.1855, -0.2561, -0.2561, -0.2562, -0.2562, -0.2668, -0.2668, -0.2669, -0.3062, -0.3062, -0.3063, -0.3063, -0.3063, -0.3063, -0.4952, -0.4952, -0.4953, -0.4953, -0.4953, -0.4953, -0.5085, -0.5085, -0.5085, -0.5085, -0.5085, -0.5085, -0.6909, -1.31, -0.9688, -0.9771, -0.8464, -0.8557, -1.2894, -0.9692, 2.364, 1.239, -0.0337, -0.1043, -0.1044, -0.1044, -0.1044, -0.1115, -0.1116, -0.115, -0.115, -0.115, -0.1544, -0.1544, -0.1544, -0.1544, -0.1545, -0.1545, -0.3434, -0.3434, -0.3435, -0.3435, -0.3435, -0.3435, -0.3567, -0.3567, -0.3567, -0.3567, -0.3567, -0.3567, -0.5391, -0.8169, -0.8253, -0.5371, -0.6946, -0.7039, -1.1376, -0.8174, 2.3639, 1.2391, -0.0337, -0.1043, -0.1043, -0.1043, -0.1044, -0.1115, -0.1116, -0.115, -0.115, -0.115, -0.1543, -0.1544, -0.1545, -0.1545, -0.1545, -0.1545, -0.3434, -0.3435, -0.3435, -0.3435, -0.3435, -0.3435, -0.3567, -0.3567, -0.3567, -0.3567, -0.3567, -0.3567, -0.817, -0.537, -0.5393, -0.8253, -0.6946, -0.7039, -1.1376, -0.8174, 0.3636, 0.3635, 0.2929, 0.2928, 0.2928, 0.2928, 0.2858, 0.2856, 0.2822, 0.2822, 0.2822, 0.2428, 0.2428, 0.2428, 0.2427, 0.2427, 0.2427, 0.0539, 0.0538, 0.0537, 0.0537, 0.0537, 0.0537, 0.0405, 0.0405, 0.0405, 0.0405, 0.0405, 0.0405, 0.0405, -0.1418, -0.4197, -0.7611, -0.4281, -0.1398, -0.2974, -0.3067, -0.7404, -0.4202]}, \"token.table\": {\"Topic\": [5, 2, 1, 1, 2, 1, 1, 2, 2, 3, 7, 3, 1, 2, 3, 5, 6, 1, 1, 6, 4, 4, 2, 7, 2, 1, 4, 5, 6, 2, 6, 1, 5, 1, 2, 2, 3, 4, 1, 1, 4, 1, 2, 3, 7, 1, 1], \"Freq\": [1.0258227304027263, 0.8163521485751161, 0.8056478092648922, 0.7379225539794076, 0.3689612769897038, 0.8056481960695975, 0.3612750616396146, 0.3612750616396146, 0.8163511555361168, 0.9861359376652497, 1.0293781678041227, 0.9861349722885443, 0.5082475892433709, 0.5082475892433709, 0.6709940842454, 0.6709940842454, 1.036766478877867, 0.8056478997777112, 0.8056488660307376, 1.0367660305773252, 0.9861368086852822, 0.9861336448215376, 0.8163516998406908, 1.0293774925017838, 0.8163500257140424, 0.5692387388288483, 0.5692387388288483, 1.0258228255619062, 1.0367659769313713, 0.8163588289747876, 1.0367630108964687, 0.8056484053144524, 1.0258252597016912, 0.5082239117781178, 0.5082239117781178, 0.5745650751898609, 0.5745650751898609, 0.9861347124660484, 0.8056484559579867, 0.8056479570155266, 0.9861362800082261, 1.008144370935948, 0.8163651191750793, 0.6725176602971139, 0.6725176602971139, 0.8056475762540148, 0.8056475466601224], \"Term\": [\"angst\", \"aspect\", \"change\", \"class\", \"class\", \"climate\", \"college\", \"college\", \"concept\", \"confidence\", \"contribute\", \"degree\", \"everybody\", \"everybody\", \"everyone\", \"everyone\", \"field\", \"friend\", \"honor\", \"information\", \"interest\", \"marine\", \"networking\", \"offer\", \"opportunity\", \"person\", \"person\", \"phase\", \"place\", \"provide\", \"regurgitate\", \"research\", \"resentment\", \"scholarship\", \"scholarship\", \"school\", \"school\", \"science\", \"session\", \"something\", \"stage\", \"study\", \"teacher\", \"thing\", \"thing\", \"undergraduate\", \"university\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 9, 7, 5, 4, 6, 10, 3, 2, 8]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement(script);\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el581405338022714408322188619\", ldavis_el581405338022714408322188619_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el581405338022714408322188619\", ldavis_el581405338022714408322188619_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el581405338022714408322188619\", ldavis_el581405338022714408322188619_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.162510 -0.049578       1        1  29.566326\n",
       "8     -0.110226  0.114946       2        1  20.695678\n",
       "6      0.103689  0.089150       3        1   8.850903\n",
       "4      0.032191 -0.138161       4        1   8.850893\n",
       "3      0.089288  0.019627       5        1   7.278552\n",
       "5      0.054692 -0.048293       6        1   7.121331\n",
       "9      0.061556  0.014985       7        1   6.335185\n",
       "2     -0.033322  0.003554       8        1   4.605624\n",
       "1     -0.033322  0.003553       9        1   4.605622\n",
       "7     -0.002037 -0.009781      10        1   2.089885, topic_info=           Term      Freq     Total Category  logprob  loglift\n",
       "0       college  2.000000  2.000000  Default  30.0000  30.0000\n",
       "38        thing  1.000000  1.000000  Default  29.0000  29.0000\n",
       "32     everyone  1.000000  1.000000  Default  28.0000  28.0000\n",
       "14      sibling  0.000000  0.000000  Default  27.0000  27.0000\n",
       "1      graduate  0.000000  0.000000  Default  26.0000  26.0000\n",
       "..          ...       ...       ...      ...      ...      ...\n",
       "38        thing  0.027020  1.486950  Topic10  -3.7134  -0.1398\n",
       "9        school  0.027016  1.740447  Topic10  -3.7135  -0.2974\n",
       "3        person  0.027015  1.756732  Topic10  -3.7136  -0.3067\n",
       "16        class  0.027014  2.710312  Topic10  -3.7136  -0.7404\n",
       "21  scholarship  0.027014  1.967637  Topic10  -3.7136  -0.4202\n",
       "\n",
       "[403 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "11        5  1.025823          angst\n",
       "26        2  0.816352         aspect\n",
       "15        1  0.805648         change\n",
       "16        1  0.737923          class\n",
       "16        2  0.368961          class\n",
       "17        1  0.805648        climate\n",
       "0         1  0.361275        college\n",
       "0         2  0.361275        college\n",
       "27        2  0.816351        concept\n",
       "37        3  0.986136     confidence\n",
       "39        7  1.029378     contribute\n",
       "31        3  0.986135         degree\n",
       "28        1  0.508248      everybody\n",
       "28        2  0.508248      everybody\n",
       "32        3  0.670994       everyone\n",
       "32        5  0.670994       everyone\n",
       "33        6  1.036766          field\n",
       "18        1  0.805648         friend\n",
       "19        1  0.805649          honor\n",
       "35        6  1.036766    information\n",
       "5         4  0.986137       interest\n",
       "2         4  0.986134         marine\n",
       "29        2  0.816352     networking\n",
       "40        7  1.029377          offer\n",
       "30        2  0.816350    opportunity\n",
       "3         1  0.569239         person\n",
       "3         4  0.569239         person\n",
       "12        5  1.025823          phase\n",
       "34        6  1.036766          place\n",
       "8         2  0.816359        provide\n",
       "36        6  1.036763    regurgitate\n",
       "20        1  0.805648       research\n",
       "13        5  1.025825     resentment\n",
       "21        1  0.508224    scholarship\n",
       "21        2  0.508224    scholarship\n",
       "9         2  0.574565         school\n",
       "9         3  0.574565         school\n",
       "4         4  0.986135        science\n",
       "22        1  0.805648        session\n",
       "23        1  0.805648      something\n",
       "6         4  0.986136          stage\n",
       "7         1  1.008144          study\n",
       "10        2  0.816365        teacher\n",
       "38        3  0.672518          thing\n",
       "38        7  0.672518          thing\n",
       "24        1  0.805648  undergraduate\n",
       "25        1  0.805648     university, R=30, lambda_step=0.01, plot_opts={xlab: PC1, ylab: PC2}, topic_order=[1, 9, 7, 5, 4, 6, 10, 3, 2, 8])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Initial demoipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
