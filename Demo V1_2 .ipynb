{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vDJXBjEn1DmM"
   },
   "outputs": [],
   "source": [
    "#Subject to change, only using one file to train initial model. \n",
    "corpus = \"So I'm a young first gen college graduate, my dad joined the military as soon as he could and my mom dropped out at 16. I never really understood how different I was until I started hanging out with people in the same major as me (Marine Science). I always felt like I missed a crucial stage growing up where my interests would've been nurtured. Most of my studies I just did independently. I hated my teachers in high school because they only seemed to provide their helping hands to the kids who needed it least. I grew a bit of an unhealthy resentment to the preppy kids in my angst-ridden phase. I never really thought of going to college, it wasn't talked about, even with my other siblings. I just kind of wound up there and more or less, ended up winging it. Fast forward a few years and I am succeeding as best I can in classes and still feel like I'm missing something despite usually being near the top of most of my classes, doing climate change research as an undergraduate, leading study sessions with people in the honors college at my university and having many intelligent and motivating friends winning prestigious scholarships. I always felt like I got the concepts of the classes but everybody else seemed to understand the networking and scholarship and opportunity aspects of college. I graduated from a big school with my degree, my peers thought very highly of me, but I always felt less than everyone else. I felt like everyone else had a plan, knew what they were doing. So fast forward some more and here I am. I finally got my first good job in my field and I never really felt more out of place than here. I want to fit in, everybody is so nice, professional and scholarly. All I know how to do is memorize information and regurgitate it on a test and somehow do well. It just feels weird. Maybe it's a confidence thing? I know I can do whatever is needed to be done, I just don't know if I have any thing new to offer or worthwhile to contribute.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process and vectorize the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "id": "MFyKGQ-x3IZV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['young',\n",
       "  'first',\n",
       "  'gen',\n",
       "  'college',\n",
       "  'graduate',\n",
       "  'dad',\n",
       "  'joined',\n",
       "  'the',\n",
       "  'military',\n",
       "  'soon',\n",
       "  'could',\n",
       "  'and',\n",
       "  'mom',\n",
       "  'dropped',\n",
       "  'out'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'understood',\n",
       "  'how',\n",
       "  'different',\n",
       "  'was',\n",
       "  'until',\n",
       "  'started',\n",
       "  'hanging',\n",
       "  'out',\n",
       "  'with',\n",
       "  'people',\n",
       "  'the',\n",
       "  'same',\n",
       "  'major',\n",
       "  'marine',\n",
       "  'science'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'missed',\n",
       "  'crucial',\n",
       "  'stage',\n",
       "  'growing',\n",
       "  'where',\n",
       "  'interests',\n",
       "  'would',\n",
       "  'been',\n",
       "  'nurtured'],\n",
       " ['most', 'studies', 'just', 'did', 'independently'],\n",
       " ['hated',\n",
       "  'teachers',\n",
       "  'high',\n",
       "  'school',\n",
       "  'because',\n",
       "  'they',\n",
       "  'only',\n",
       "  'seemed',\n",
       "  'provide',\n",
       "  'their',\n",
       "  'helping',\n",
       "  'hands',\n",
       "  'the',\n",
       "  'kids',\n",
       "  'who',\n",
       "  'needed',\n",
       "  'least'],\n",
       " ['grew',\n",
       "  'bit',\n",
       "  'unhealthy',\n",
       "  'resentment',\n",
       "  'the',\n",
       "  'preppy',\n",
       "  'kids',\n",
       "  'angst',\n",
       "  'ridden',\n",
       "  'phase'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'thought',\n",
       "  'going',\n",
       "  'college',\n",
       "  'wasn',\n",
       "  'talked',\n",
       "  'about',\n",
       "  'even',\n",
       "  'with',\n",
       "  'other',\n",
       "  'siblings'],\n",
       " ['just', 'kind', 'wound', 'there', 'and', 'more', 'less', 'ended', 'winging'],\n",
       " ['fast',\n",
       "  'forward',\n",
       "  'few',\n",
       "  'years',\n",
       "  'and',\n",
       "  'succeeding',\n",
       "  'best',\n",
       "  'can',\n",
       "  'classes',\n",
       "  'and',\n",
       "  'still',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'missing',\n",
       "  'something',\n",
       "  'despite',\n",
       "  'usually',\n",
       "  'being',\n",
       "  'near',\n",
       "  'the',\n",
       "  'top',\n",
       "  'most',\n",
       "  'classes',\n",
       "  'doing',\n",
       "  'climate',\n",
       "  'change',\n",
       "  'research',\n",
       "  'undergraduate',\n",
       "  'leading',\n",
       "  'study',\n",
       "  'sessions',\n",
       "  'with',\n",
       "  'people',\n",
       "  'the',\n",
       "  'honors',\n",
       "  'college',\n",
       "  'university',\n",
       "  'and',\n",
       "  'having',\n",
       "  'many',\n",
       "  'intelligent',\n",
       "  'and',\n",
       "  'motivating',\n",
       "  'friends',\n",
       "  'winning',\n",
       "  'prestigious',\n",
       "  'scholarships'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'got',\n",
       "  'the',\n",
       "  'concepts',\n",
       "  'the',\n",
       "  'classes',\n",
       "  'but',\n",
       "  'everybody',\n",
       "  'else',\n",
       "  'seemed',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'networking',\n",
       "  'and',\n",
       "  'scholarship',\n",
       "  'and',\n",
       "  'opportunity',\n",
       "  'aspects',\n",
       "  'college'],\n",
       " ['graduated',\n",
       "  'from',\n",
       "  'big',\n",
       "  'school',\n",
       "  'with',\n",
       "  'degree',\n",
       "  'peers',\n",
       "  'thought',\n",
       "  'very',\n",
       "  'highly',\n",
       "  'but',\n",
       "  'always',\n",
       "  'felt',\n",
       "  'less',\n",
       "  'than',\n",
       "  'everyone',\n",
       "  'else'],\n",
       " ['felt',\n",
       "  'like',\n",
       "  'everyone',\n",
       "  'else',\n",
       "  'had',\n",
       "  'plan',\n",
       "  'knew',\n",
       "  'what',\n",
       "  'they',\n",
       "  'were',\n",
       "  'doing'],\n",
       " ['fast', 'forward', 'some', 'more', 'and', 'here'],\n",
       " ['finally',\n",
       "  'got',\n",
       "  'first',\n",
       "  'good',\n",
       "  'job',\n",
       "  'field',\n",
       "  'and',\n",
       "  'never',\n",
       "  'really',\n",
       "  'felt',\n",
       "  'more',\n",
       "  'out',\n",
       "  'place',\n",
       "  'than',\n",
       "  'here'],\n",
       " ['want', 'fit', 'everybody', 'nice', 'professional', 'and', 'scholarly'],\n",
       " ['all',\n",
       "  'know',\n",
       "  'how',\n",
       "  'memorize',\n",
       "  'information',\n",
       "  'and',\n",
       "  'regurgitate',\n",
       "  'test',\n",
       "  'and',\n",
       "  'somehow',\n",
       "  'well'],\n",
       " ['just', 'feels', 'weird'],\n",
       " ['maybe', 'confidence', 'thing'],\n",
       " ['know',\n",
       "  'can',\n",
       "  'whatever',\n",
       "  'needed',\n",
       "  'done',\n",
       "  'just',\n",
       "  'don',\n",
       "  'know',\n",
       "  'have',\n",
       "  'any',\n",
       "  'thing',\n",
       "  'new',\n",
       "  'offer',\n",
       "  'worthwhile',\n",
       "  'contribute']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize the document in differnt parts(sentences, words) and lemmatize. \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "import gensim \n",
    "\n",
    "#Split the doucment into sentences. \n",
    "nltk.download('punkt')\n",
    "list_of_sentences = sent_tokenize(corpus)\n",
    "list_of_sentences\n",
    "\n",
    "#Deaccent and remove some basic stopwords with gensim. \n",
    "list_of_sentences_data = []\n",
    "for i in list_of_sentences:\n",
    "  list_of_sentences_data.append(gensim.utils.simple_preprocess(i, deacc= True, min_len = 3))\n",
    "\n",
    "#Remove any numbers, but not words that contain numbers in them. \n",
    "list_of_sentences_data = [[token for token in data if not token.isnumeric()]for data in list_of_sentences_data]\n",
    "\n",
    "#Remove words that contain only one charcter. \n",
    "list_of_sentences_data = [[token for token in data if len(token) > 1]for data in list_of_sentences_data]\n",
    "\n",
    "list_of_sentences_data \n",
    "\n",
    "##Split the document into tokens. #Alternative \n",
    "\n",
    "#from nltk.tokenize.regexp import RegexpTokenizer\n",
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#for i in range(len(list_of_sentences_data)):\n",
    "    #list_of_sentences_data[i] = list_of_sentences_data[i].lower() # Convert into lowercase. \n",
    "    #list_of_sentences_data[i] = tokenizer.tokenize(list_of_sentences_data[i]) #Split into words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "#from gensim.utilis import lemmatize ##lemmatize for V3 \n",
    "import re\n",
    "\n",
    "#adding bigrams to docs for chratcter that only appear 20 times or more. \n",
    "bigram = Phrases(list_of_sentences_data, min_count=20)\n",
    "bigram \n",
    "\n",
    "#In case prompted to install 'stopwords', use \"nltk.download('stopwords')\".\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Lemmatize the documents.#Alternative\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Funtion to lemmatize, apply bigrams and tokenize the given data set.\n",
    "def process_texts(texts):\n",
    "   texts = [[word for word in line if word not in stops] for line in texts] #tokenize the do\n",
    "   texts = [bigram[line] for line in texts]\n",
    "   texts = [[lemmatizer.lemmatize(token) for token in doc] for doc in texts]\n",
    "   #texts = [word.encode(\"utf-8\").split('/')[0] for word in texts]\n",
    "   return texts\n",
    "    # lemmatize the document(Other methods can be used to execute this. This method is best when working on collab or with gensim V3,gensim.utils has been dropped for V4)\n",
    "    # texts = [[word.decode(\"utf-8\").split('/')[0] for word in lemmatize(' '.join(line), allowed_tags=re.compile('(NN)'), min_length=5)] for line in texts]\n",
    "  \n",
    "     #trigrams_ = [t for t in trigram[bigram[sent]] if t.count(' ') == 2]\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "id": "YBbn1X-MCLQR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pattern in c:\\program files\\python310\\lib\\site-packages (3.6)\n",
      "Requirement already satisfied: cherrypy in c:\\program files\\python310\\lib\\site-packages (from pattern) (18.6.1)\n",
      "Requirement already satisfied: feedparser in c:\\program files\\python310\\lib\\site-packages (from pattern) (6.0.10)\n",
      "Requirement already satisfied: scipy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (1.8.1)\n",
      "Requirement already satisfied: python-docx in c:\\program files\\python310\\lib\\site-packages (from pattern) (0.8.11)\n",
      "Requirement already satisfied: lxml in c:\\program files\\python310\\lib\\site-packages (from pattern) (4.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (4.11.1)\n",
      "Requirement already satisfied: pdfminer.six in c:\\program files\\python310\\lib\\site-packages (from pattern) (20220524)\n",
      "Requirement already satisfied: backports.csv in c:\\program files\\python310\\lib\\site-packages (from pattern) (1.0.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (1.22.3)\n",
      "Requirement already satisfied: requests in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (2.27.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pattern) (3.7)\n",
      "Requirement already satisfied: future in c:\\program files\\python310\\lib\\site-packages (from pattern) (0.18.2)\n",
      "Requirement already satisfied: mysqlclient in c:\\program files\\python310\\lib\\site-packages (from pattern) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from beautifulsoup4->pattern) (2.3.2.post1)\n",
      "Requirement already satisfied: jaraco.collections in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (3.5.1)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (3.1.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (8.6.0)\n",
      "Requirement already satisfied: more-itertools in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (8.13.0)\n",
      "Requirement already satisfied: zc.lockfile in c:\\program files\\python310\\lib\\site-packages (from cherrypy->pattern) (2.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\program files\\python310\\lib\\site-packages (from feedparser->pattern) (1.0.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (2022.6.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (4.64.0)\n",
      "Requirement already satisfied: click in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from nltk->pattern) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pdfminer.six->pattern) (2.0.12)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\program files\\python310\\lib\\site-packages (from pdfminer.six->pattern) (36.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\program files\\python310\\lib\\site-packages (from requests->pattern) (1.26.8)\n",
      "Requirement already satisfied: six>=1.11.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.16.0)\n",
      "Requirement already satisfied: jaraco.functools in c:\\program files\\python310\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\program files\\python310\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.0)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\program files\\python310\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern) (5.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk->pattern) (0.4.4)\n",
      "Requirement already satisfied: jaraco.classes in c:\\program files\\python310\\lib\\site-packages (from jaraco.collections->cherrypy->pattern) (3.2.1)\n",
      "Requirement already satisfied: jaraco.text in c:\\program files\\python310\\lib\\site-packages (from jaraco.collections->cherrypy->pattern) (3.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from zc.lockfile->cherrypy->pattern) (62.6.0)\n",
      "Requirement already satisfied: pycparser in c:\\program files\\python310\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
      "Requirement already satisfied: pytz in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.1)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in c:\\program files\\python310\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\MoRevolution\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "id": "feTaBeJ9JgXZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young',\n",
       "  'first',\n",
       "  'gen',\n",
       "  'college',\n",
       "  'graduate',\n",
       "  'dad',\n",
       "  'joined',\n",
       "  'military',\n",
       "  'soon',\n",
       "  'could',\n",
       "  'mom',\n",
       "  'dropped'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'understood',\n",
       "  'different',\n",
       "  'started',\n",
       "  'hanging',\n",
       "  'people',\n",
       "  'major',\n",
       "  'marine',\n",
       "  'science'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'missed',\n",
       "  'crucial',\n",
       "  'stage',\n",
       "  'growing',\n",
       "  'interest',\n",
       "  'would',\n",
       "  'nurtured'],\n",
       " ['study', 'independently'],\n",
       " ['hated',\n",
       "  'teacher',\n",
       "  'high',\n",
       "  'school',\n",
       "  'seemed',\n",
       "  'provide',\n",
       "  'helping',\n",
       "  'hand',\n",
       "  'kid',\n",
       "  'needed',\n",
       "  'least'],\n",
       " ['grew',\n",
       "  'bit',\n",
       "  'unhealthy',\n",
       "  'resentment',\n",
       "  'preppy',\n",
       "  'kid',\n",
       "  'angst',\n",
       "  'ridden',\n",
       "  'phase'],\n",
       " ['never',\n",
       "  'really',\n",
       "  'thought',\n",
       "  'going',\n",
       "  'college',\n",
       "  'talked',\n",
       "  'even',\n",
       "  'sibling'],\n",
       " ['kind', 'wound', 'le', 'ended', 'winging'],\n",
       " ['fast',\n",
       "  'forward',\n",
       "  'year',\n",
       "  'succeeding',\n",
       "  'best',\n",
       "  'class',\n",
       "  'still',\n",
       "  'feel',\n",
       "  'like',\n",
       "  'missing',\n",
       "  'something',\n",
       "  'despite',\n",
       "  'usually',\n",
       "  'near',\n",
       "  'top',\n",
       "  'class',\n",
       "  'climate',\n",
       "  'change',\n",
       "  'research',\n",
       "  'undergraduate',\n",
       "  'leading',\n",
       "  'study',\n",
       "  'session',\n",
       "  'people',\n",
       "  'honor',\n",
       "  'college',\n",
       "  'university',\n",
       "  'many',\n",
       "  'intelligent',\n",
       "  'motivating',\n",
       "  'friend',\n",
       "  'winning',\n",
       "  'prestigious',\n",
       "  'scholarship'],\n",
       " ['always',\n",
       "  'felt',\n",
       "  'like',\n",
       "  'got',\n",
       "  'concept',\n",
       "  'class',\n",
       "  'everybody',\n",
       "  'else',\n",
       "  'seemed',\n",
       "  'understand',\n",
       "  'networking',\n",
       "  'scholarship',\n",
       "  'opportunity',\n",
       "  'aspect',\n",
       "  'college'],\n",
       " ['graduated',\n",
       "  'big',\n",
       "  'school',\n",
       "  'degree',\n",
       "  'peer',\n",
       "  'thought',\n",
       "  'highly',\n",
       "  'always',\n",
       "  'felt',\n",
       "  'le',\n",
       "  'everyone',\n",
       "  'else'],\n",
       " ['felt', 'like', 'everyone', 'else', 'plan', 'knew'],\n",
       " ['fast', 'forward'],\n",
       " ['finally',\n",
       "  'got',\n",
       "  'first',\n",
       "  'good',\n",
       "  'job',\n",
       "  'field',\n",
       "  'never',\n",
       "  'really',\n",
       "  'felt',\n",
       "  'place'],\n",
       " ['want', 'fit', 'everybody', 'nice', 'professional', 'scholarly'],\n",
       " ['know', 'memorize', 'information', 'regurgitate', 'test', 'somehow', 'well'],\n",
       " ['feel', 'weird'],\n",
       " ['maybe', 'confidence', 'thing'],\n",
       " ['know',\n",
       "  'whatever',\n",
       "  'needed',\n",
       "  'done',\n",
       "  'know',\n",
       "  'thing',\n",
       "  'new',\n",
       "  'offer',\n",
       "  'worthwhile',\n",
       "  'contribute']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = process_texts(list_of_sentences_data)\n",
    "train_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x2dc44571900>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1\n",
      "Number of documents: 19\n"
     ]
    }
   ],
   "source": [
    "# Remove rare and common tokens.\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(train_texts)\n",
    "dictionary\n",
    "\n",
    "# Filter out words that occur more than 50% of the documents.\n",
    "dictionary.filter_extremes(no_above=0.5)\n",
    "\n",
    "# Bag-of-words representation of the documents.\n",
    "corpus = [dictionary.doc2bow(text) for text in train_texts]\n",
    "\n",
    "#See how mnay tokens and documents we have to train on. \n",
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "#print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Edw7Y3MIJnLK"
   },
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make an index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=num_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: nan.\n",
      "[([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan),\n",
      " ([(1.0, 'felt')], nan)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MoRevolution\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\MoRevolution\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "top_topics = model.top_topics(corpus)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "id": "cskTzFfzR-Kp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pyLDAvis in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (3.3.1)\n",
      "Requirement already satisfied: numexpr in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.22.3)\n",
      "Requirement already satisfied: funcy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.17)\n",
      "Requirement already satisfied: future in c:\\program files\\python310\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: gensim in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (4.2.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.4.2)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from pyLDAvis) (62.6.0)\n",
      "Requirement already satisfied: sklearn in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pyLDAvis) (1.8.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from gensim->pyLDAvis) (0.29.28)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->pyLDAvis) (2.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn->pyLDAvis) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\morevolution\\appdata\\roaming\\python\\python310\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 951
    },
    "collapsed": true,
    "id": "vhwBJnIhT9VZ",
    "outputId": "607d7393-24e0-42c4-ba97-9a7d0bbf94e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\past\\builtins\\misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "C:\\Users\\MoRevolution\\AppData\\Roaming\\Python\\Python310\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1665631451865801129097344036\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1665631451865801129097344036_data = {\"mdsDat\": {\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"y\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [61.69368068806852, 5.080087272369645, 4.353418042082553, 4.262003522447992, 4.168055209543374, 4.158678132985218, 4.071024964192977, 4.071022058466751, 4.0710152039330865, 4.071014905909884]}, \"tinfo\": {\"Term\": [\"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\", \"felt\"], \"Freq\": [5.0, 3.0846842527389526, 0.2540043815970421, 0.21767091751098633, 0.21310019120573997, 0.20840277522802353, 0.20793392136693, 0.2035512626171112, 0.20355111733078957, 0.2035507746040821, 0.2035507597029209], \"Total\": [5.0, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578, 5.000000353902578], \"Category\": [\"Default\", \"Topic1\", \"Topic2\", \"Topic3\", \"Topic4\", \"Topic5\", \"Topic6\", \"Topic7\", \"Topic8\", \"Topic9\", \"Topic10\"], \"logprob\": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"loglift\": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, \"token.table\": {\"Topic\": [1], \"Freq\": [0.5999999575316936], \"Term\": [\"felt\"]}, \"R\": 1, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 9, 10, 3, 7, 8, 2, 6, 1, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1665631451865801129097344036\", ldavis_el1665631451865801129097344036_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1665631451865801129097344036\", ldavis_el1665631451865801129097344036_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1665631451865801129097344036\", ldavis_el1665631451865801129097344036_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=         x    y  topics  cluster       Freq\n",
       "topic                                      \n",
       "3      0.0  0.0       1        1  61.693681\n",
       "8      0.0  0.0       2        1   5.080087\n",
       "9      0.0  0.0       3        1   4.353418\n",
       "2      0.0  0.0       4        1   4.262004\n",
       "6      0.0  0.0       5        1   4.168055\n",
       "7      0.0  0.0       6        1   4.158678\n",
       "1      0.0  0.0       7        1   4.071025\n",
       "5      0.0  0.0       8        1   4.071022\n",
       "0      0.0  0.0       9        1   4.071015\n",
       "4      0.0  0.0      10        1   4.071015, topic_info=   Term      Freq  Total Category  logprob  loglift\n",
       "0  felt  5.000000    5.0  Default      1.0      1.0\n",
       "0  felt  3.084684    5.0   Topic1      0.0      0.0\n",
       "0  felt  0.254004    5.0   Topic2      0.0      0.0\n",
       "0  felt  0.217671    5.0   Topic3      0.0      0.0\n",
       "0  felt  0.213100    5.0   Topic4      0.0      0.0\n",
       "0  felt  0.208403    5.0   Topic5      0.0      0.0\n",
       "0  felt  0.207934    5.0   Topic6      0.0      0.0\n",
       "0  felt  0.203551    5.0   Topic7      0.0      0.0\n",
       "0  felt  0.203551    5.0   Topic8      0.0      0.0\n",
       "0  felt  0.203551    5.0   Topic9      0.0      0.0\n",
       "0  felt  0.203551    5.0  Topic10      0.0      0.0, token_table=      Topic  Freq  Term\n",
       "term                   \n",
       "0         1   0.6  felt, R=1, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 9, 10, 3, 7, 8, 2, 6, 1, 5])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(model, corpus, dictionary)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Demo V1.1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
